{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f50ad00",
   "metadata": {},
   "source": [
    "**Author:** Shahab Fatemi\n",
    "\n",
    "**Email:** shahab.fatemi@umu.se   ;   shahab.fatemi@amitiscode.com\n",
    "\n",
    "**Created:** 2025-06-01\n",
    "\n",
    "**Last update:** 2025-09-23\n",
    "\n",
    "**MIT License** ‚Äî Shahab Fatemi (2025); For use in the *Machine Learning in Physics* course, Ume√• University, Sweden; See the full license text in the parent folder.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccda5ee",
   "metadata": {},
   "source": [
    "üì¢ <span style=\"color:red\"><strong> Note for Students:</strong></span>\n",
    "\n",
    "* Before working on the labs, review your lecture notes.\n",
    "\n",
    "* Please read all sections, code blocks, and comments **carefully** to fully understand the material. Throughout the labs, my instructions are provided to you in written form, guiding you through the materials step-by-step.\n",
    "\n",
    "* All concepts covered in this lab are part of the course and may be included in the final exam.\n",
    "\n",
    "* I strongly encourage you to work in pairs and discuss your findings, observations, and reasoning with each other.\n",
    "\n",
    "* If something is unclear, don't hesitate to ask.\n",
    "\n",
    "* I have done my best to make the lab files as bug-free (and error-free) as possible, but remember: *there is no such thing as bug-free code.* If you observed any bugs, errors, typos, or other issues, I would greatly appreciate it if you report them to me by email. Verbal notifications are not work, as I will likely forget üôÇ\n",
    "\n",
    "ENJOY WORKING ON THIS LAB.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2603e8",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Purpose and Learning Outcomes:\n",
    "\n",
    "The main focus of this lab is to guide you through the principles and practical application of data analysis and learn how to apply Gaussian Naive Bayes (GNB) for classification tasks. This notebook is relatively rich in data analysis, which I am sure will be useful for purposes beyond this course. It covers various aspects of statistical data analysis and the ML workflow. \n",
    "Learning goals include: \n",
    "- Understanding the theory behind Gaussian Naive Bayes, \n",
    "- exploring and learning feature distributions using Kernel Density Estimates (KDE), histograms, and QQ plots, \n",
    "- training and evaluating a GNB classifier with sklearn, \n",
    "- interpreting confusion matrices and classification reports, and \n",
    "- visualizing decision boundaries for non-linear high-dimensional data. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../utils'))\n",
    "from notebook_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb40b7",
   "metadata": {},
   "source": [
    "***\n",
    "‚ùó <span style=\"color:red\"><strong> Important:</strong></span>\n",
    "\n",
    "Due to consistently low attendance in the lab sessions (<10 per session and I've never seen a few of you in the lab at all), I am unable to assess whether the lab material is being properly understood or not. Therefore, starting from this lab, submitting your answers to the sections marked as \"‚ö° Mandatory\" will be required within the given deadline for each session. This is not applied to the earlier labs.\n",
    "\n",
    "- Your answers for the \"‚ö° Mandatory\" sections of each lab <span style=\"color:red\"><strong>must be submitted before the start of the next lab session</strong></span> (e.g., for this lab is by September 26, at 13:15).\n",
    "\n",
    "- You may submit either a handwritten version (on paper) or an electronic version.\n",
    "\n",
    "- **Submission:** Write all your answers in one single file (either PDF, Word document, or simple text) and email it to me or write all on a paper and hand it to me in person.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ae491",
   "metadata": {},
   "source": [
    "# Naive Bayes: overview\n",
    "\n",
    "Naive Bayes is a probabilistic `classification` algorithm based on Bayes' theorem. While it can, in principle, be applied to regression, it is primarily used for `classification` tasks. The key assumption is that each feature ${x_k}$ is conditionally independent of the others given the class label, y. This \"naive\" assumption greatly simplifies the computation of the posterior probability ${P(y‚à£x)}$, since it allows the joint likelihood to be expressed as a product of individual feature likelihoods. The algorithm also avoids computing the full marginal probability ${P(x)}$ since it cancels out in the normalization.\n",
    "\n",
    "Gaussian Naive Bayes (GNB) is a widely used variant of the Naive Bayes that assumes continuous features follow a Gaussian (normal) distribution. This generative approach makes it particularly suitable for datasets with continuous variables, or the number of features are exessivly large compared to the data samples. GNB is often applied in domains where efficient classification is required and the Gaussian assumption provides a reasonable approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277930fa",
   "metadata": {},
   "source": [
    "## Exploring Gaussian Naive Bayes (GNB)\n",
    "\n",
    "In this lab, you will investigate the GNB algorithm using a dataset that contains three features (x1, x2, and x3) and one text-based label (y). We first need to convert the text label into a numeric format. Then we will visualize the distributions of the features, fit a GNB model, and evaluate its performance. The dataset is developed by me, located in the \"dataset\" folder, and we will load it from there for our analysis. \n",
    "\n",
    "**For now, forget the \"Gaussian\" distribution, and GNB. We will come back to it.**\n",
    "\n",
    "Before doing anything, lets load the data using pandas, and explore it. If you do not remember pandas, review `Python_Jumpstart/05-Data_Analysis.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770dc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset with 3 features and 1 text-based label. Ignore loading comments in the CSV file.\n",
    "df = pd.read_csv(\"../datasets/Gaussian_Naive_Bayes.csv\", comment=\"#\")\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d1a20e",
   "metadata": {},
   "source": [
    "Open the file \"../datasets/Gaussian_Naive_Bayes.csv\" with your text editor and review its content. \n",
    "\n",
    "‚ö†Ô∏è Before beginning any analysis (both in this course and in general practice) carefully inspect the file: check the headers, labels, and any additional notes or housekeeping information it may contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data shape and column names\n",
    "print(\"Number of rows in the file:\", df.shape[0])\n",
    "print(\"Number of columns in the file:\", df.shape[1])\n",
    "print(\"Column names:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91b06d",
   "metadata": {},
   "source": [
    "The \"y\" column contains text labels. Let's identify and display all unique label values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92023c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique labels in column \"y\"\n",
    "unique_labels = df[\"y\"].unique()\n",
    "print(\"Unique labels in 'y':\", unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271c23",
   "metadata": {},
   "source": [
    "We convert the text labels into numeric format using sklearn's `LabelEncoder`. This step is crucial because ML algorithms require numeric input, not text labels. If you want, you can instead use NumPy's unique function, but requires further machinary to use it in your model: https://numpy.org/devdocs/reference/generated/numpy.unique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f89257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "y_encoded = label_encoder.fit_transform(df['y'])\n",
    "\n",
    "# Display the unique numeric labels\n",
    "print(\"Unique numeric labels:\", set(y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print label mapping\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32f79b",
   "metadata": {},
   "source": [
    "The code comments explain what has been done! If you do not understand, ask your neighbor classmate, or you can ask me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e594da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original labels in a new column\n",
    "df[\"y_original\"] = df[\"y\"]\n",
    "\n",
    "# Convert categorical labels to integers and update the dataframe\n",
    "df[\"y\"] = y_encoded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025b26c",
   "metadata": {},
   "source": [
    "List all available features in the dataset excluding the target variable (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in [\"y\", \"y_original\"]]\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7189b385",
   "metadata": {},
   "source": [
    "Split the dataset into training and testing (validation) sets and form new dataframes for each. Note that I've used 30\\% of the data for testing, and used shuffle=True and stratify=y to ensure that the data and class labels are correctly distributed in both training and testingsets. If you do not remember it from earlier labs, please review: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[feature_cols]    # Select feature columns\n",
    "y = df[\"y\"]             # Select the label column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, # 30% for testing\n",
    "                                                    stratify=y,    # Ensure proportional representation of classes\n",
    "                                                    shuffle=True,  # Shuffle the data\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Combine X_train and y_train into one DataFrame (df_train). \n",
    "# This is for plotting purposes in seaborn, and not a necessary step for modeling.\n",
    "df_train = X_train.copy()\n",
    "df_train[\"y\"] = y_train.copy()\n",
    "\n",
    "# Combine X_test and y_test into one DataFrame (df_test) for later use\n",
    "df_test = X_test.copy()\n",
    "df_test[\"y\"] = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a42234",
   "metadata": {},
   "source": [
    "The function below visualizes the distributions of specified features in a given DataFrame by creating two plots for each feature: a Kernel Density Estimate (KDE) plot and a histogram combined with the KDE of each feature in the dataset, but before that, let's review the KDE, and its differences compared to classical histogram.\n",
    "\n",
    "### KDE vs. Histogram\n",
    "Kernel Density Estimation (KDE) is a non-parametric statistical method used to estimate the probability density function (PDF) of a random variable. Unlike parametric methods, KDE **does not** assume that the data follow a specific distribution (such as Gaussian), which makes it very flexible.\n",
    "\n",
    "Compared to a histogram, which groups data into bins and can produce a discontinuous shape depending on the chosen bin size, KDE produces a smooth and continuous curve that better captures the structure of the data. The figure below taken from Wikipedia (https://en.wikipedia.org/wiki/Kernel_density_estimation) nicely shows the difference between a histogram and a KDE:\n",
    "![My figure](../figures/Comparison_of_1D_histogram_and_KDE.png)\n",
    "\n",
    "KDE is particularly useful when working with small or moderate sample sizes, where histograms may look irregular and cannot provide meaningful patterns. While histograms remain a simple and valid tool, I recommend to develop a habit of visualizing data with KDE.\n",
    "\n",
    "Study the figure above, and compare the histogram with the KDE plot. Do you understand how the KDE works? Do you see the purpose of the dashed red-lines in the KDE plot? discuss it with your neighbor classmate, and if you are unsure, ask me.\n",
    "\n",
    "Later in this course, we will discuss non-parametric models in more detail and explore the role of kernel functions beyond density estimation, especially in the context of algorithms such as Support Vector Machines.\n",
    "\n",
    "You can also read more on Density Estimators from: https://scikit-learn.org/stable/modules/density.html\n",
    "\n",
    "Let's visualize the distributions of specified features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# plot KDE and Histogram for each feature\n",
    "def plot_distributions(df, features):\n",
    "    fig, axes = plt.subplots(2, len(features), \n",
    "                    figsize=(5*len(features), 8), dpi=200)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        # KDE plot\n",
    "        sns.kdeplot(df[feature], fill=True, \n",
    "                    color=\"#4991d9\", \n",
    "                    lw=2, ax=axes[0, i])\n",
    "        axes[0, i].set_xlabel(feature)\n",
    "        axes[0, i].set_ylabel(\"Density\")\n",
    "        axes[0, i].set_title(f\"KDE {feature}\")\n",
    "        axes[0, i].grid(True)\n",
    "\n",
    "        # Histogram with KDE\n",
    "        sns.histplot(df[feature], kde=True, \n",
    "                     bins=25, \n",
    "                     color=\"#B25FB5\", \n",
    "                     edgecolor=\"k\", \n",
    "                     lw=2, ax=axes[1, i])\n",
    "        axes[1, i].set_xlabel(feature)\n",
    "        axes[1, i].set_ylabel(\"Counts\")\n",
    "        axes[1, i].set_title(f\"Histogram {feature}\")\n",
    "        axes[1, i].grid(True)\n",
    "\n",
    "    plt.suptitle(\"Feature distributions (Training Set)\", fontsize=20, weight=\"bold\")\n",
    "    plt.show()\n",
    "\n",
    "# Call on training data\n",
    "plot_distributions(X_train, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c52278",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- Examine the histogram and KDE plots for each feature. What do these plots show you about the data distribution? NOTE: The purple curve superimposed on each histogram is indeed the KDE line. However, note that the horizontal axis ranges in the top panels differ from those in the corresponding bottom panels.\n",
    "\n",
    "- How do different features compare in shape and spread? Remember that axis ranges are different between features and between the KDE and histogram plots. Consider this difference in your interpretation.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7507bc0",
   "metadata": {},
   "source": [
    "The code below generates KDE plots for every one of the features (${x_1, x_2, x_3}$) within different classes of our target variable, $y$. It creates a series of KDEs for each feature, showing $P(x_i | y)$. The results look very similar to the plot you have in your lecture notes (see the last slides)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde_by_class(df, features):\n",
    "    fig, axes = plt.subplots(1, len(features), figsize=(6*len(features), 6), dpi=200)\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Filled KDE plot\n",
    "        sns.kdeplot(data=df, x=feature, hue=\"y\", fill=True, common_norm=False, alpha=0.2,\n",
    "                    ax=ax, palette=\"muted\")\n",
    "\n",
    "        # Overlay line KDE plot for clarity\n",
    "        sns.kdeplot(data=df, x=feature, hue=\"y\", common_norm=False, lw=3,\n",
    "                    ax=ax, palette=\"muted\", legend=False)\n",
    "\n",
    "        ax.set_xlabel(feature, fontsize=20)\n",
    "        ax.set_ylabel(f\"P({feature} | Y=y)\", fontsize=20)\n",
    "        ax.set_title(f\"KDE {feature}\", fontsize=22, weight=\"bold\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call with training data\n",
    "plot_kde_by_class(df_train, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3bbc6",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚ö° Mandatory submission\n",
    "- The plots above show a visual presentation of $P(x_k | y)$. What does it mean and how is it different from $P(x_k)$? Write your answer in a short paragraph (see the submission instruction at the beginning of this notebook). \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50131f96",
   "metadata": {},
   "source": [
    "### Quantile-Quantile (QQ) Analysis\n",
    "\n",
    "As mentioned earlier, our goal is to use Gaussian Naive Bayes (GNB) to train the model and provide probabilistic estimates for the data. In the previous step, we applied KDE to visualize the feature distributions. The next question is: how well does a \"Gaussian\" (normal) distribution describe our data? To evaluate this, we turn to Quantile‚ÄìQuantile (QQ) analysis.\n",
    "\n",
    "A **quantile** is a statistical term. It refers to values that divide a dataset into equal-sized intervals. For example,  median is a special case of a quantile that divides the dataset into two equal halves. \n",
    "\n",
    "Quantiles are a fundamental statistical concept that provide valuable information on the distribution of data, such as identifying skewness or the presence of outliers. A Quantile-Quantile (QQ) plot shows the quantiles of the feature's values against the quantiles of the theoretical distribution (often a Gausian distribution or a distribution obtained from a KDE). If the points on the QQ plot lie approximately along a straight 45-degree line, it suggests that the feature's distribution closely matches the theoretical distribution. If you have forgotten what the QQ plot is, visit https://www.geeksforgeeks.org/machine-learning/quantile-quantile-plots/ and \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html\n",
    "\n",
    "Side note: A commonly use quantile is the `Percentil` that divides data into 100 equal parts.\n",
    "\n",
    "Below, we show the QQ plot for the features in our dataset to visually assess how closely the distributions of these features approximate a Gaussian distribution. This allows us to identify deviations from normality, which is a very important analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def plot_qq_plots(df, features):\n",
    "    fig, axes = plt.subplots(1, len(features), figsize=(6*len(features), 5), dpi=200)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        # Get theoretical quantiles and ordered values\n",
    "        (osm, osr), (slope, intercept, r) = stats.probplot(df[feature], dist=\"norm\")\n",
    "        \n",
    "        ## ----------------------------------------------------------------\n",
    "        ## NOTE: If you want to test other distributions, you can change the dist parameter \n",
    "        #   to \"uniform\", \"expon\", \"lognorm\", etc.\n",
    "        #   Find the full list from https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "        #   However, for GNB, we are interested in \"norm\".\n",
    "        ## ----------------------------------------------------------------\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.scatter(osm, osr, marker=\"o\", s=70, color=\"tomato\", alpha=0.7)\n",
    "        ax.plot(osm, osm*slope + intercept, \"--\", color=\"k\", lw=2)  # Reference line\n",
    "\n",
    "        ax.set_xlabel(\"Theoretical Quantiles\", fontsize=20)\n",
    "        ax.set_ylabel(\"Ordered Values\", fontsize=20)\n",
    "        ax.set_title(f\"Q-Q plot for {feature}\", fontsize=22, weight=\"bold\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call with training data\n",
    "plot_qq_plots(X_train, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e70f4d",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚ö° Mandatory submission\n",
    "Carefully analyze the QQ plot above. What do the deviations from the dashed line mean? Write your answers in one short paragraph.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266c178",
   "metadata": {},
   "source": [
    "Let's perform further analysis of our data using pairplot and boxplot. We'd used them before in the Python Jumpstart, file 03-Data_Plotting.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d39def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pair_and_box(df):\n",
    "    plt.figure()\n",
    "    sns.pairplot(df, hue=\"y\", diag_kind=\"kde\", palette=\"bright\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=df.drop(columns=\"y\"))\n",
    "    plt.title(\"Boxplot of features\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_pair_and_box(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed774031",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- The code section above is very simple to understand, and its presented outcomes are very important. What do you observe? Do you understand the distribution of the features and their relation?\n",
    "\n",
    "***\n",
    "\n",
    "### ‚ö° Mandatory submission\n",
    "- What does the box plot for the ${x_1}$ feature tell us about the data distribution? Explain all your observations in a short paragraph.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56de19c",
   "metadata": {},
   "source": [
    "The code below shows you how to use `Seaborn` for marginal data visualization. This is mainly for you to see different variations in data analysis and visualizations. It creates a customized jointplot of two features (`x1` and `x3`) from a dataset, combining a scatter plot with a regression line in the center and marginal histograms with KDE Gaussian distributions. This setup allows you to explore both the joint distribution and the individual feature distributions in a visually informative way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Define color palette\n",
    "palette_color = \"#1fb435\"  # Green for points\n",
    "line_color    = \"#ff7f0e\"  # Orange for regression line\n",
    "kde_color     = \"#005f73\"  # Deep blue for KDE\n",
    "hist_color    = \"#98c1d9\"  # Light blue for hist bars\n",
    "\n",
    "# Optional: pre-set figure (not required for jointplot itself)\n",
    "plt.figure(figsize=(10, 6), dpi=120)\n",
    "\n",
    "# Create jointplot\n",
    "jn = sns.jointplot(\n",
    "    data=df_train,\n",
    "    x=\"x1\",\n",
    "    y=\"x3\",\n",
    "    kind=\"reg\",\n",
    "    height=8,\n",
    "    ratio=5,\n",
    "    space=0.3,\n",
    "    scatter_kws={\n",
    "        \"s\": 60,\n",
    "        \"color\": palette_color,\n",
    "        \"marker\": \"o\",\n",
    "        \"edgecolor\": \"k\",\n",
    "        \"alpha\": 0.7\n",
    "    },\n",
    "    line_kws={\n",
    "        \"color\": line_color,\n",
    "        \"linewidth\": 2,\n",
    "        \"linestyle\": \"--\"\n",
    "    },\n",
    "    marginal_kws={\"bins\": 30, \"color\": hist_color}\n",
    ")\n",
    "\n",
    "jn.set_axis_labels(\"Feature x1\", \"Feature x3\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41865ae",
   "metadata": {},
   "source": [
    "Now we have explored our data and we want to train a Gaussian Naive Bayes model using the features and plot the confusion matrix (contingency table). I do not think you need my explanation on what has been done below! Study the code, run it, and carefully analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def train_evaluate(df_train, df_test, features):\n",
    "    X_train = df_train[features]  # Select features\n",
    "    y_train = df_train[\"y\"]          # Class Labels\n",
    "    \n",
    "    X_test = df_test[features]\n",
    "    y_test = df_test[\"y\"]\n",
    "\n",
    "    # Standardize features and create a pipeline with Gaussian Naive Bayes\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"gnb\", GaussianNB())\n",
    "    ])\n",
    "    \n",
    "    # Fit the model and make predictions\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Perform cross-validation to evaluate the model\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "    print(f\"Cross-validation Accuracy: {scores.mean():.2f} ¬± {scores.std():.2f}\")\n",
    "        \n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"---------------------------------------------\\n\")\n",
    "        \n",
    "    # Print/plot confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix: \\n\", cm)\n",
    "        \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                  display_labels=np.unique(y))\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()    \n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "train_evaluate(df_train, df_test, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e13000",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- Carefully analyze the classification report and the confusion matrix. How good is our classifier?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1187c5",
   "metadata": {},
   "source": [
    "Below we visualize the decision boundaries of our GNB classifier, trained on two selected features from a dataset. We only do that for two of the provided features because we show the boundary in a 2D plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557a6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundaries(pipe, df, features):\n",
    "    assert len(features) == 2, \"Decision boundaries can only be plotted for 2D data.\"\n",
    "\n",
    "    X = df[features].values\n",
    "    y = df[\"y\"].values\n",
    "    \n",
    "    scaler = pipe.named_steps[\"scaler\"]    # Get the scaler from the pipeline\n",
    "    gnb    = pipe.named_steps[\"gnb\"]       # Get the Gaussian Naive Bayes model from the pipeline\n",
    "\n",
    "    # Create a grid for plotting decision boundaries\n",
    "    X_scaled = scaler.fit_transform(X)  # Scale the features\n",
    "    \n",
    "    # Define the grid limits with a margin for better visualization\n",
    "    # Adjust the margin to ensure the decision boundaries are clearly visible\n",
    "    x_min, x_max = X_scaled[:, 0].min() - 1, X_scaled[:, 0].max() + 1\n",
    "    y_min, y_max = X_scaled[:, 1].min() - 1, X_scaled[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    # Predict the class labels for the grid points\n",
    "    predicted = gnb.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, predicted, cmap=ListedColormap([\"#8F8FEE\",\"#F49696\", \"#92F792\"]), alpha=0.5)\n",
    "    scatter = plt.scatter(X_scaled[:, 0], X_scaled[:, 1], s=30, c=y, edgecolors=\"k\", cmap=\"brg\", alpha=0.7)\n",
    "    \n",
    "    plt.xlabel(features[0])\n",
    "    plt.ylabel(features[1])\n",
    "    plt.title(\"Decision Boundaries (Scaled Data)\")\n",
    "    plt.legend(*scatter.legend_elements(), title=\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "# For 2D visualization, we will use only x1 and x2\n",
    "features_2d = [\"x1\", \"x2\"]\n",
    "pipe_2d = train_evaluate(df_train, df_test, features_2d)\n",
    "\n",
    "plot_decision_boundaries(pipe_2d, df_test , features_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cdc07b",
   "metadata": {},
   "source": [
    "We usually focus on decision boundaries from the test set, but it is also useful to look at the training set to check how well the model has learned from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ecbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(pipe_2d, df_train, features_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afe9fc",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- Carefully analyze the classification report and ensure you understand the meaning of each metric. \n",
    "\n",
    "- Modify the selected feature pair from $[x_1, x_2]$ to $[x_1, x_3]$ and to $[x_2, x_3]$, running the decision boundary code each time. You can execute them in separate code cells to more easily compare the results and observe how the classifier's performance and boundaries change with different feature combinations.\n",
    "\n",
    "### ‚ö° Mandatory submission\n",
    "\n",
    "- What is your model accuracy when using the ${[x_1, x_3]}$ and how is it different from using ${[x_1, x_2]}$? Explain your observations in a short paragraph.\n",
    "\n",
    "- Find line \n",
    "```python\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "```\n",
    "in the code section above. What does the `fit_transform` method do in the context of the `StandardScaler`? Explain its purpose and how it differs from using `fit` and `transform` separately. Write your answer in a short paragraph.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ac260",
   "metadata": {},
   "source": [
    "# ‚õ∑Ô∏è Exercise\n",
    "\n",
    "### Stellar Data Analysis for Gaussian Naive Bayes (GNB)\n",
    "\n",
    "In this exercise, you will analyze a dataset that shows the properties of stars based on their astrophysical principles. The dataset contains information about stellar parameters, including **Mass**, **Radius**, **Temperature**, and **Luminosity**. Most of the values are normalized with respect to our Sun: The **Mass** is given in solar masses, the **Radius** in solar radii, the **Temperature** in Kelvin, and the **Luminosity** is normalized to solar luminosity. \n",
    "\n",
    "Your objective is to analyze the data, explore the relationships between the given parameters, and develop regression models to predict target values (i.e., luminosity) based on given features (i.e., mass, radius, and temperature). You will also explore the use of Gaussian Naive Bayes (GNB) in a regression context, which is typically more suited for classification tasks.\n",
    "\n",
    "**Note:** GNB is primarily a classification algorithm, but for the purpose of this exercise (i.e., education and practice), you will learn how to adapt it for regression tasks by discretizing the target variable (luminosity) into categorical classes. \n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Begin with loading the stellar dataset using the code below. The luminosity is calculated using the Stefan-Boltzmann Law, and it contains noise.\n",
    "\n",
    "   ```python\n",
    "   # Load Luminosity Dataset\n",
    "   import pandas as pd\n",
    "\n",
    "   data = pd.read_csv(\"../datasets/stellar_luminosity.csv\", comment=\"#\")\n",
    "   ```\n",
    "\n",
    "2. Visualize the distributions of the data. Use pair plots, histograms, and correlation matrices to perform a comprehensive analysis. This will help you understand the data structure, identify patterns, and observe the relationships between parameters such as mass, radius, temperature, and luminosity. \n",
    "\n",
    "3. Start by implementing a regression model using techniques you have learned so far, such as polynomial regression or linear regression to predict luminosity. Assess the model's performance using cross-validation to calculate the R2-score, Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). These metrcis will quantify the model's accuracy in predicting luminosity based on the other features.\n",
    "\n",
    "4. Next, you will implement GNB. Since predicting a continuos target like luminosity is not suitable for GNB, you need to discretize the luminosity values into categories (e.g., low, medium, high). This transformation allows you to treat the problem as a `classification` task. After discretization, you can train the GNB model and evaluate its performance using accuracy metrics, confusion matrices, and classification reports. Compare the results of GNB with your regression model to analyze the differences in performance.\n",
    "\n",
    "5. Finally, visualize your results by plotting the predictd versus actual luminosity values. Additionally, analyse the residuals (the difference between predicted and actual values) to assess the performance of your models. Create histograms and scatter plots of the residuals to intprepret their distribution and identify any patterns. Discuss the accuracy of both models and potential biases that may influence their predictions.\n",
    "\n",
    "### Important to consider\n",
    "\n",
    "The GNB is primarily designed for classification tasks. The key considerations include:\n",
    "\n",
    "- Transforming the continuous target variable (luminosity) into discrete categories allows GNB to apply its probabilistic framework. \n",
    "\n",
    "- GNB operates under the assumption that the features are conditionally independent given the class label. This assumption may not hold in the context of your astrophysical data, where parameters like mass and radius can be correlated. Understanding these limitations is crucial for interpreting GNB's predictions.\n",
    "\n",
    "- By comparing GNB's performance with a traditional regression model, you will learn the strnghts and weaknesses of using a classification approach for predicting continuous outcomes. This analysis will highlight the importance of **selecting the appropriate model** based on the **nature of the data** and the specific task at hand.\n",
    "\n",
    "\n",
    "***\n",
    "END\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
