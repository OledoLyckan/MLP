{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Shahab Fatemi\n",
    "\n",
    "**Email:** shahab.fatemi@umu.se   ;   shahab.fatemi@amitiscode.com\n",
    "\n",
    "**Created:** 2024-04-19\n",
    "\n",
    "**Last update:** 2025-09-07\n",
    "\n",
    "**MIT License** ‚Äî Shahab Fatemi (2025); For use in the *Machine Learning in Physics* course, Ume√• University, Sweden; See the full license text in the parent folder.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì¢ <span style=\"color:red\"><strong> Note for Students:</strong></span>\n",
    "\n",
    "* Before working on the labs, review your lecture notes.\n",
    "\n",
    "* Please read all sections, code blocks, and comments **carefully** to fully understand the material. Throughout the labs, my instructions are provided to you in written form, guiding you through the materials step-by-step.\n",
    "\n",
    "* All concepts covered in this lab are part of the course and may be included in the final exam.\n",
    "\n",
    "* I strongly encourage you to work in pairs and discuss your findings, observations, and reasoning with each other.\n",
    "\n",
    "* If something is unclear, don't hesitate to ask.\n",
    "\n",
    "* Exercise submission is not required; these tasks are designed to help you practice, explore the concepts, and learn by doing.\n",
    "\n",
    "* I have done my best to make the lab files as bug-free (and error-free) as possible, but remember: *there is no such thing as bug-free code.* If you observed any bugs, errors, typos, or other issues, I would greatly appreciate it if you report them to me by email. Verbal notifications are not work, as I will likely forget üôÇ\n",
    "\n",
    "ENJOY WORKING ON THIS LAB.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Purpose and Learning Outcomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab, you (we) worked on a linear function, $h(x)=w_0 + w^Tx$. In this lab, we move to a high-degree polynomail function and we want to apply the OLS (closed-form) solution to our non-linear problems.\n",
    "\n",
    "You will learn about:\n",
    "* feature augmentation\n",
    "* feature normalization\n",
    "* workflow pipelines\n",
    "* data splitting\n",
    "* model training\n",
    "* cross validation\n",
    "\n",
    "I modified this lab from its original notebook to make it ready as soon as possible for your lab session. In case, something was confusing or inconsistent, please report it to me.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, **we need data** to train our model.\n",
    "\n",
    "We simulate the motion of a projectile by calculating the true displacement over time using the equation of motion, $y(t) = -(1/2)gt^2 + v_0t + y_0$. To mimic the real world measurement error, we add gaussian noise to the data using `np.random.normal` function. The aim is to fit a line into the generated data, which will be conducted in the next sections.\n",
    "\n",
    "Let's generate and visualize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    Creating a list of colors based on the \"tab10\" colormap.\n",
    "    I want to use the color set in the \"tab10\" colormap for my plotting.\n",
    "\"\"\"\n",
    "cmap = plt.colormaps[\"tab10\"]\n",
    "colors = [cmap(i) for i in range(21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Simulate the motion of a projectile\n",
    "# Compute the true y values for the motion of a projectile\n",
    "def projectile_motion(g, v0, y0, time_range=(0, 5), num_points=100, noise_level=5, seed=42):\n",
    "    np.random.seed(seed)  # Set random seed for reproducibility\n",
    "    \n",
    "    # time for the projectile motsion\n",
    "    t = np.linspace(time_range[0], time_range[1], num_points)\n",
    " \n",
    "    # The projectile equation is y = -(1/2)*g*t^2 + v0*t + y0\n",
    "    y_true  = -0.5*g*t**2 + v0*t + y0 # true trajectory\n",
    "    y_noisy = y_true + np.random.normal(0, noise_level, num_points) # noisy data\n",
    "    return t, y_true, y_noisy\n",
    "\n",
    "# Plot the projectile motion\n",
    "# NOTE: This function visualizes the projectile motion and its noisy observations.\n",
    "# However, I've also included an option to visualize the fitted polynomial regression.\n",
    "# If the fitting data is provided, the function will plot the regression curve as well;\n",
    "# otherwise, it will only show the projectile motion and noisy observations.\n",
    "# I've done this because I want to call this function again later.\n",
    "def plot_data(t, y_true, y_noisy, x_fit=None, y_fit=None, poly_degree=None, title=\"Projectile Motion\"):\n",
    "    # Use high dpi for high-quality output. \n",
    "    #  Usually any dpi between 200 and 300 is good for publications.\n",
    "    #  Never use dpi<=100. The default for dpi in plt.figure() is 100.\n",
    "    # My recommendation is dpi=300, especially for reports and publications, \n",
    "    # however, dpi=300 may create larger file sizes, and large figures on your screen, \n",
    "    # but you can try ...!\n",
    "    plt.figure(figsize=(6, 4), dpi=200)\n",
    "\n",
    "    # Plot the noisy data\n",
    "    # Use scatter plot to visualize data distribution, and remember to use alpha<1.0 for transparency.\n",
    "    # If the reason for alpha<1 is not clear for you, ask me or discuss it with your friends.\n",
    "    plt.scatter(t, y_noisy, color=colors[1], s=40, edgecolors=\"k\", alpha=0.6, label=f\"Noisy data\")\n",
    "\n",
    "    # Plot the true projectile motion curve\n",
    "    if (y_true is not None):\n",
    "        plt.scatter(t, y_true, color=colors[0], s=5, label=\"True y\")\n",
    "\n",
    "    # Plot the polynomial regression fit if provided\n",
    "    if (x_fit is not None and \n",
    "        y_fit is not None):\n",
    "        label_text = f\"Polynomial degree {poly_degree}\" if poly_degree is not None else \"Regression fit\"\n",
    "        plt.scatter(x_fit, y_fit, color=colors[2], s=2, label=label_text)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "    plt.ylabel(\"Displacement (m)\", fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", color=\"grey\", linewidth=0.5, alpha=0.6)\n",
    "    plt.tight_layout() # Fit all elements within the figure area\n",
    "    plt.show()\n",
    "\n",
    "# ======== MAIN ========\n",
    "# Parameters for the projectile motion simulation\n",
    "v0 = 25.0  # initial velocity (m/s)\n",
    "g  = 9.8   # gravity acceleration (m/s^2)\n",
    "y0 = 0.0   # initial position/height/displacement (m)\n",
    "n  = 100   # number of points (#)\n",
    "time_range  = (0, 5)  # time range from 0 to 5 seconds\n",
    "noise_level = 5       # standard deviation of the noise\n",
    "\n",
    "# Construct data\n",
    "t, y_true, y_noisy = projectile_motion(g, v0, y0, time_range, n, noise_level)\n",
    "\n",
    "# Visualize the noisy and true trajectoory of the projectile.\n",
    "plot_data(t, y_true, y_noisy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ü§ì Tips: Polish final figures\n",
    "\n",
    "Many of you will work on data analysis or even get a job as a data analyist after graduation. Here is my suggestion (recommendation) to you based on my personal experience: When you analyze data, your figures are the first thing people notice (of course the quality of the analysis are above that). So make the figures and final products clear and easy to read. You spend a lot of time on analyzing the data, so why not spending some time on final touch-ups like choosing good colors, labeling axes properly, adding a legend, and making sure your plots are not too crowded or too blured. These small improvements can make a big difference in how others understand and appreciate your work. It is a good habit to always check your figures before using them in a report or presentation. Ask yourself: Is everything readable? Does the figure tell the story I want it to tell? But don't overdo it. Keep it simple, consistent, and clean. A well-made figure can often say a lot more than a full paragraph.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basis Function (Polynomial) Regression\n",
    "\n",
    "**Overview:** Basis functions transform the original input features into a new set of features to capture complex relationships in the data. Here, we want to use $\\phi_j(x)=x^j$ (see lecture notes).\n",
    "\n",
    "Now we perform polynomial regression to fit a line into the (assuming) \"measured\" data. We use the closed-form solution (OLS: Ordinary Least Squares estimator) to calculate the coefficients of the polynomial. We construct the `Vandermonde` matrix for the input values ${x}$ based on the specified polynomial degree. Then,, we compute the weight vector ${w}$ using the OLS formula: \n",
    "\n",
    "$w = (x^T x)^{-1} x^T y$, \n",
    "\n",
    "where, from now on, ${x}$ is the Vandermonde matrix and ${y}$ is the output noisy displacement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit (train) polynomial using closed-form solution\n",
    "def fit_polynomial_OLS(x, y, degree):\n",
    "    # Form the Vandermonde matrix for x\n",
    "    X = np.vander(x, degree + 1, increasing=True)\n",
    "    \n",
    "    # Closed-form solution: w = (X^T * X)^(-1) * X^T * y\n",
    "    # The @ operator is matrix multiplication, equivalent to np.matmul()\n",
    "    w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return w\n",
    "\n",
    "# Predict polynomial values given coefficients\n",
    "def predict_polynomial_OLS(x, coeffs):\n",
    "    return np.polyval(coeffs[::-1], x)\n",
    "\n",
    "poly_degree = 5  # degree of the polynomial function\n",
    "\n",
    "# Regression on noisy data for polynomial degree of poly_degree\n",
    "w = fit_polynomial_OLS(t, y_noisy, poly_degree)\n",
    "\n",
    "# print coefficients/parameters of the model\n",
    "print(\"\\nPredicted Coefficients w:\")\n",
    "for i, coef in enumerate(w):\n",
    "    print(f\"w{i} = {coef:+.2f}\")\n",
    "\n",
    "# Generate new t values to predict its y values (y^*) using our trained model\n",
    "t_vals = np.linspace(time_range[0], time_range[1], 3*n)  # This is new input values\n",
    "y_pred = predict_polynomial_OLS(t_vals, w)   # This is y^* in the lecture notes\n",
    "\n",
    "plot_data(t, y_true, y_noisy, x_fit=t_vals, y_fit=y_pred, poly_degree=poly_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### üí° Reflect and Run\n",
    "\n",
    "- Check the shape of matrix ${X}$ formed by the Vandermonde in `fit_polynomial_OLS` and compare its share with your input matrix, `{t}`.\n",
    "\n",
    "- Try experimenting with different polynomial degrees (e.g., 1, 2, 7, or 10) to see how the model changes. A low-degree polynomial may *underfit* the data and a very high-degree polynomial may *overfit* and capture noise and memorize all patterns. Observing this behavior is a great way to understand the bias-variance tradeoff.\n",
    "\n",
    "- Compare the coefficients you got from different polynomial degrees with the true coefficients of your function ${y(t)}$.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ì Why 42?\n",
    "\n",
    "Did you notice I used \"42\" in setting my random seeds?\n",
    "You see this \"42\" everywhere when we set our seeds to a specific number for data reproducebility. The number comes from the novel \"The Hitchhiker's Guide to the Galaxy\" By Douglas Adams in 1979. \"Throughout all versions, the series follows the adventures of Arthur Dent, a hapless Englishman, following the destruction of the Earth by the Vogons (a race of unpleasant and bureaucratic aliens) to make way for a hyperspace bypass. In their travels, Arthur comes to learn that the Earth was actually a giant supercomputer, created by another supercomputer, `Deep Thought`. Deep Thought had been built by its creators to give the answer to the *'Ultimate Question of Life, the Universe, and Everything'*, which, after eons of calculations, was given simply as `42`.\" [Ref: Wikipedia]\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization, and Pipeline with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the this section, we use \"SciKitLearn\" (sklearn) pre-developed functions instead of our self-developed OLS form. In this section, you are going to learn new practical aspects of ML: i.e., \n",
    "\n",
    "   - data normalization and \n",
    "   - forming pipelines.\n",
    "\n",
    "The code below \"fits\" a polynomial regression model of a specified degree to our noisy data of the projectile, and normalizes the input features for improved numerical stability and better model performance. The normalized parameters allow scaling of the input data (t) to have a mean of 0 and a standard deviation of 1 using `StandardScaler`. This process is called **feature scaling** or **Standardization** or **Normalization**, which is important for ML algorithms that are sensitive to the scale of input data.\n",
    "\n",
    "Read more: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "I've made the normalization as an optional setting, so one can choose to use or not use it.\n",
    "\n",
    "Additionally, we use a SciKit-Learn `pipeline` to streamline the process by combining normalization (if enabled), polynomial feature generation, and linear regression into a single, efficient workflow. \n",
    "\n",
    "Read more: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "Notes: \n",
    "1. The pipeline is an important concept as it combines data transformation and model fitting in a single step. This ensures a streamlined workflow, and therefore it minimizes errors in a developed code. It also helps you to provide a code clarity which is essential for consistency in ML applications where preprocessing and modeling need to be efficiently managed and tested.\n",
    "\n",
    "2. In the code belew, we use `x.reshape(-1,1)` to convert a 1D array into 2D because sk-learn takes input features in the shape of $n \\times p$: (n_samples, p_features). To understand how it works, you can test this in a separate code section:\n",
    "```python\n",
    "    a = np.array([1, 2, 3])\n",
    "    print(a)\n",
    "    print(a.reshape(-1, 1))\n",
    "    print(a.reshape(1, -1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit (train) polynomial regression model using sklearn pipeline\n",
    "def fit_polynomial_sklearn(x, y, degree=2, normalize=True):\n",
    "    if(normalize):\n",
    "        # Create a pipeline with normalization\n",
    "        model = make_pipeline(StandardScaler(), \n",
    "                              PolynomialFeatures(degree), \n",
    "                              LinearRegression())\n",
    "    else:\n",
    "        # Create a pipeline without normalization\n",
    "        model = make_pipeline(PolynomialFeatures(degree), \n",
    "                              LinearRegression())\n",
    "\n",
    "    # We need to use x.reshape, as required by sklearn\n",
    "    model.fit(x.reshape(-1, 1), y)\n",
    "    return model\n",
    "\n",
    "# Predict polynomial values at new input data using the trained model\n",
    "def predict_polynomial_sklearn(model, x_vals):\n",
    "    return model.predict(x_vals.reshape(-1, 1))\n",
    "\n",
    "# Print the coefficients of the trained sklearn model from the pipeline\n",
    "def print_model_coefficients(model):\n",
    "    lr = model.named_steps['linearregression']\n",
    "    coef = lr.coef_\n",
    "    intercept = lr.intercept_\n",
    "\n",
    "    print(f\"Intercept: {intercept:.4f}\")\n",
    "    for i, c in enumerate(coef):\n",
    "        print(f\"w_{i}: {c:.4f}\")\n",
    "        \n",
    "def plot_multiple_fits(t, y_true, y_noisy, degrees, normalize=True, title=\"Polynomial Regression\"):\n",
    "    plt.figure(figsize=(6, 4), dpi=200)\n",
    "\n",
    "    # Plot noisy data\n",
    "    plt.scatter(t, y_noisy, color=colors[1], s=40, edgecolors=\"k\", alpha=0.6, label=\"Noisy data\")\n",
    "\n",
    "    # Plot true function\n",
    "    plt.scatter(t, y_true, color=colors[0], s=5, label=\"True y\")\n",
    "\n",
    "    # Generate dense grid for smooth predictions\n",
    "    t_vals = np.linspace(min(t), max(t), 3*t.size)\n",
    "\n",
    "    # Plot polynomial fits for each degree\n",
    "    for idx, deg in enumerate(degrees):\n",
    "        model  = fit_polynomial_sklearn(t, y_noisy, degree=deg, normalize=normalize)\n",
    "        y_pred = predict_polynomial_sklearn(model, t_vals)\n",
    "        color  = colors[idx + 1]  # offset by 1 since colors[0] used for true y\n",
    "        plt.plot(t_vals, y_pred, color=color, linewidth=2, label=f\"Polynom d={deg}\")\n",
    "\n",
    "    plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "    plt.ylabel(\"Displacement (m)\", fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", color=\"grey\", linewidth=0.5, alpha=0.6)    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========== MAIN ==========\n",
    "# Fit polynomial regression models and plot\n",
    "degrees = [1, 5, 15] # degrees of the polynomial\n",
    "plot_multiple_fits(t, y_true, y_noisy, degrees, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### üí° Reflect and Run\n",
    "\n",
    "- Modify the code to print the polynomial coefficients (weights) computed by the sklearn model for each polynomial degree. Then compare them with the coefficients you obtained earlier using the closed-form OLS solution. Explore the similarities and differences of the results. Observe how close the coefficients are, especially for lower-degree polynomials, and think about why they might differ more as the degree increases.\n",
    "\n",
    "- Investigate the role of normalization in the pipeline by switching the `normalize` ON and OFF in the `plot_multiple_fits` function. Try this for a few polynomial degrees and observe the changes in the fitted curves and coefficients. Does normalization help the model perform better in the presence of noise, and did the shape of the fit is noticeably affected? Perhaps only focus on the coefficients made by the polmynoial degree 5.\n",
    "\n",
    "- You can also increase the noise level in the data and examine your findings on a new more noisy data. You can increase noise level by increading `noise_level` from 5 to e.g., 10 in the very first code section in this notebook. Discuss your conclusions with your peers. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "I want you to re-produce data overfitting through lowering the number of samples. The code below procudes that for you. Note that I've decrease sample points to n=12 in the code below. We see an \"extreme\" overfitting when the number of data (n) is equal to or smaller than the number of polynomial degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_example():\n",
    "    # Parameters for the projectile motion simulation\n",
    "    v0 = 25.0         # initial velocity (m/s)\n",
    "    g  = 9.8          # gravity acceleration (m/s^2)\n",
    "    y0 = 0.0          # initial position/height/displacement (m)\n",
    "    n_samples = 12    # number of points (#)\n",
    "    noise_lvl = 5     # standard deviation of the noise level\n",
    "        \n",
    "    # Generate data with a quadratic form and some noise\n",
    "    t, y_true, y_noisy = projectile_motion(g, v0, y0, num_points=n_samples, noise_level=noise_lvl, seed=42)\n",
    "\n",
    "    # Define degrees of polynomials to fit\n",
    "    degrees = [2, 7, 12]\n",
    "    plot_multiple_fits(t, y_true, y_noisy, degrees)\n",
    "\n",
    "# ========== MAIN ==========\n",
    "# Run the overfit example\n",
    "overfit_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### üí° Reflect and Run\n",
    "- Set the polynomial degrees to `degrees = [1, 3, 13]` and run the code. Observe how each model fits the data, especially the one with degree \"13\", which is higher than the number of data points. What does it tells you about overfitting in polynomial regression? You can also test higher degrees, e.g., 22.\n",
    "\n",
    "- Finally, return to `degrees = [1, 3, 13]`, but now significantly increase the number of data points to `n = 1000` (or higher, e.g., 10000). Rerun the code and examine how each model responds to this denser dataset. Pay particular attention to the high degree polynomials and discuss on how increasing the amount of data affects model flexibility and the ability to **generalize**.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Polynomial Degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a new data using a high order polynomials. We also separate our data into training and validation sets. For data splitting, we sue sklearn's `train_test_split`, assuming 70% of the data is used for training and 30% for validation. As I said, the \"validation\" and \"test\" terms are used interchangably. Since the function is named `train_test_split`, we also call our sets train and \"test\", but we know that the \"test\" set is for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Data generation function\n",
    "def generate_new_data(a=+1, b=-5, c=+3, x_range=(-2, 2), \n",
    "                      num_points=100, noise_level=3.0, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    x = np.linspace(x_range[0], x_range[1], num_points)\n",
    "    y_true = a * x**5 + b * x**3 + c * x\n",
    "    y_noisy = y_true + np.random.normal(0, noise_level, num_points)\n",
    "    return x, y_true, y_noisy\n",
    "\n",
    "# ========== MAIN ==========\n",
    "# Parameters\n",
    "a = +1\n",
    "b = -7\n",
    "c = +3\n",
    "n = 100\n",
    "x_range = (-2.5, 2.5)\n",
    "noise_level = 7.0\n",
    "\n",
    "# Generate data\n",
    "x, y_true, y_noisy = generate_new_data(a, b, c, x_range, n, noise_level)\n",
    "\n",
    "# Randomly split data (both true and noisy) into training and test sets\n",
    "x_train, x_test, y_train_noisy, y_test_noisy, y_train_true, y_test_true = train_test_split(\n",
    "    x, y_noisy, y_true, test_size=0.3, random_state=42)\n",
    "\n",
    "# Plot only the training set\n",
    "plot_data(x_train, y_true=y_train_true, y_noisy=y_train_noisy, title=\"Training Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given the dataset above that follows a non-linear function, and our task is to fit a polynomial regression model to the data. One of the key challenges in this process is determining the appropriate degree \"d\" for the polynomial. A degree that is too low may result in underfitting (simple model), and a degree that is too high can lead to overfitting (complex model). We want neither of them. \n",
    "\n",
    "The goal is to identify the \"optimal\" degree that balances model complexity and **generalization**. In this section, we want to explore how different values of \"d\" (or degrees) affect the results obtained from our model. In our example, we test degrees = [2, 3, 5, 8]. The question is, which of these degrees is most optimal value? Let's find out!\n",
    "\n",
    "First, we plot our predictions obtained from our regression model for different polynomial degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [2, 3, 5, 8] # degrees of the polynomial\n",
    "plot_multiple_fits(x_train, y_train_true, y_train_noisy, degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the issue discussed above, we assess the performance of the regression models across various polynomial degrees by computing three evaluation metrics: MSE, RMSE, and MAE score. You can also include R2 score if you want. For each polynomial degree, we use the trained model to make predictions, calculate the metrics, and plot the results to visualize how model accuracy changes with increasing model's complexity. Remember that `prediction` should be applied on the validation/test data.\n",
    "\n",
    "For those of you not familiar with Python: Skip the code in the function, and read the lines of code after the function. Then move up and study the function. If complicated to trace, you're welcome to ASK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# Function to validate models and plot the results\n",
    "# This functions evaluates the performance of polynomial regression models.\n",
    "# It computes metrics like MSE, MAE, and RMSE for each model.\n",
    "# Its input includes the feature matrix (x), true target values (y_true),\n",
    "# a list of trained models, and their corresponding polynomial degrees.\n",
    "def validate_poly_models(x, y_true, models, degrees):\n",
    "    mse_values  = []\n",
    "    mae_values  = []\n",
    "    rmse_values = []\n",
    "\n",
    "    for model in models:\n",
    "        # Predict y values using the model\n",
    "        y_pred = model.predict(x[:, np.newaxis])\n",
    "\n",
    "        mse  = mean_squared_error(y_true, y_pred)       # Calculate MSE\n",
    "        mae  = mean_absolute_error(y_true, y_pred)       # Calculate MAE\n",
    "        rmse = root_mean_squared_error(y_true, y_pred)   # Calculate RMSE\n",
    "\n",
    "        # Store the metrics for plotting\n",
    "        mse_values.append(mse)\n",
    "        mae_values.append(mae)\n",
    "        rmse_values.append(rmse)\n",
    "\n",
    "    plt.figure(figsize=(5, 4), dpi=300)\n",
    "\n",
    "    # Plot metrics\n",
    "    # Note: For better visualization, I use a logarithmic scale for the y-axis.\n",
    "    plt.semilogy(degrees, mse_values , marker=\"o\", markersize=5, color=colors[0], linestyle=\"-\" , label=\"MSE\" )\n",
    "    plt.semilogy(degrees, mae_values , marker=\"^\", markersize=5, color=colors[1], linestyle=\"-\" , label=\"MAE\" )\n",
    "    plt.semilogy(degrees, rmse_values, marker=\"s\", markersize=5, color=colors[2], linestyle=\"--\", label=\"RMSE\")\n",
    "\n",
    "    # Set x-ticks\n",
    "    plt.xticks(degrees)\n",
    "\n",
    "    # Plot\n",
    "    plt.xlabel(\"Polynomial Degree\", fontsize=14)\n",
    "    plt.ylabel(\"Metric Value\", fontsize=14)\n",
    "    plt.title(\"Model Validation Metrics\", fontsize=14, weight=\"bold\") # Here I show how to bold the title\n",
    "    plt.legend(fontsize=10, title_fontsize=12)\n",
    "    plt.grid(True, linestyle=\"--\", color=\"grey\", linewidth=0.5, alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========== MAIN ==========\n",
    "# degrees of the polynomial\n",
    "# We give these as input to our training model\n",
    "degrees = np.linspace(1, 12, 12, dtype=int)\n",
    "\n",
    "# We train data with different polynomial degrees and return the models into \n",
    "#  an array for use in the validation function.\n",
    "models  = [fit_polynomial_sklearn(x_train, y_train_noisy, degree) for degree in degrees]\n",
    "\n",
    "# Validate the models and show the metrics\n",
    "validate_poly_models(x_test, y_test_noisy, models, degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- Study the figure above. Which of the polynomial degrees is the most optimal value, and why?\n",
    "\n",
    "- Why does the metric value increase after a certain polynomial degree?\n",
    "\n",
    "- How much does the noise level and number of sample points affect the results? Change only one of the at a time, re-run the code and observe associated changes.\n",
    "\n",
    "### ‚õ∑Ô∏è Exercise (Do it yourself!)\n",
    "Write a code that trains polynomial regression models of varying degrees and computes the RMSE for both the training and validation/test sets. Plot the RMSE values as a function of polynomial degree and identify the generalization error.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this section, you need to install an extra package `mlextend`:\n",
    "\n",
    "If you use pip3:\n",
    "```bash\n",
    "    $ pip3 install mlxtend\n",
    "```\n",
    "\n",
    "If you use pip:\n",
    "```bash\n",
    "    $ pip install mlxtend\n",
    "```\n",
    "\n",
    "If you use conda:\n",
    "```bash\n",
    "    $ conda install conda-forge::mlxtend\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**overview** \n",
    "The bias-variance tradeoff shows the balance between two sources of error that can affect the performance of predictive models: bias and variance.\n",
    "\n",
    "#### Bias \n",
    "It measures how far a model's average predictions are from the true values.\n",
    "* High bias: model is too simple (e.g. underfitting)\n",
    "* Low bias: model can capture the patterns well\n",
    "\n",
    "#### Variance:\n",
    "It measures how much the model's predictions vary if we train it on different datasets. The variance between models.\n",
    "* High variance: model is too sensitive to noise and outliers (e.g. overfitting)\n",
    "* Low variance: model is stable on different training sets\n",
    "\n",
    "#### Total MSE error\n",
    "MSE = $\\text{Bias}^2$ + Variance + irreducible¬†noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "# ========== MAIN ==========\n",
    "# Parameters\n",
    "a = +1\n",
    "b = -7\n",
    "c = +3\n",
    "n = 500\n",
    "x_range = (-2.5, 2.5)\n",
    "noise_level = 4.0\n",
    "\n",
    "# Generate data\n",
    "x, y_true, y_noisy = generate_new_data(a, b, c, x_range, n, noise_level)\n",
    "\n",
    "# Randomly split data (both true and noisy) into training and test sets\n",
    "x_train, x_test, y_train_noisy, y_test_noisy, y_train_true, y_test_true = train_test_split(\n",
    "    x, y_noisy, y_true, test_size=0.3, random_state=42)\n",
    "\n",
    "degrees = np.arange(1, 15, dtype=int)\n",
    "models  = [fit_polynomial_sklearn(x_train, y_train_noisy, degree) for degree in degrees]\n",
    "\n",
    "mse_list   = []\n",
    "bias2_list = []\n",
    "var_list   = []\n",
    "\n",
    "# Loop over models\n",
    "for model in models:\n",
    "    mse, bias2, var = bias_variance_decomp(\n",
    "        model,\n",
    "        X_train=x_train.reshape(-1, 1),\n",
    "        y_train=y_train_noisy,\n",
    "        X_test=x_test.reshape(-1, 1),\n",
    "        y_test=y_test_noisy,\n",
    "        loss='mse', num_rounds=20, random_seed=42)\n",
    "    \n",
    "    mse_list.append(mse)\n",
    "    bias2_list.append(bias2)\n",
    "    var_list.append(var)\n",
    "\n",
    "# Plot bias-variance trade-off\n",
    "plt.figure(figsize=(8, 5), dpi=200)\n",
    "plt.semilogy(degrees, mse_list, label='Total MSE Error', marker='o')\n",
    "plt.semilogy(degrees, bias2_list, label=r'$Bias^2$', marker='s')\n",
    "plt.semilogy(degrees, var_list, label='Variance', marker='^')\n",
    "\n",
    "plt.xlabel(\"Polynomial Degree\", fontsize=14)\n",
    "plt.ylabel(\"Error\", fontsize=14)\n",
    "plt.title(\"Bias-Variance Trade-off\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- What do you observe from the bias-variance decomposition plot?\n",
    "\n",
    "- How does the trend in $bias^2$, variance, and total error help you identify the optimal polynomial degree for your model?\n",
    "\n",
    "### üí° Reflect and Run\n",
    "- Try changing the number of training samples, the noise level, and the true polynomial degree of the data. Vary one factor at a time, then explore combinations of changes. Observe how each change affects bias-variance, and the model's generalization performance.\n",
    "\n",
    "- You can change the parameters `(a, b, c)` for your data generator function `generate_new_data` and re-run all the analysis above for your new data. Additionally, if you want, you can create your own data generator and work on your own data. For example, I suggest generating data using this function:\n",
    "```python\n",
    "        def polysine(x, \n",
    "                    poly_coeffs=[2, -3, 0, 1], \n",
    "                    sine_amp=3.0, \n",
    "                    sine_freq=4.0, \n",
    "                    noise_level=1.0, \n",
    "                    seed=42):\n",
    "\n",
    "            # Polynomial part\n",
    "            poly = np.polyval(poly_coeffs, x)\n",
    "\n",
    "            # Sine-wave part\n",
    "            sine = sine_amp * np.sin(sine_freq * x)\n",
    "\n",
    "            # Noise\n",
    "            np.random.seed(seed)\n",
    "            noise = np.random.normal(0, noise_level, size=x.shape)\n",
    "\n",
    "            return poly + sine + noise\n",
    "```\n",
    "\n",
    "Do you understand how the data is generated using the function above? Can you write the $f(x)$?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "\n",
    "Imagine you have a set of experimental data, and you want to build a model to predict outcomes based on that data. You could just use all your data to train your model, but that would not tell you how well it will work on new data. Cross Validation is like running multiple experiments with different conditions to see how well your model works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a k-fold cross validation to evaluate the performance of our regression model for various polynomial degrees. The code below splits the dataset into k subsets (folds), shuffling the data each time to ensure randomness. For each fold, it trains the model on the training set and evaluates it on the validation set, calculating the RMSE for each degree of the polynomial. The average RMSE for each polynomial degree is then computed across all folds, providing a measure of the model's **generalization** performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# This function performs k-fold cross-validation for a given model function (polynomial) \n",
    "# and a set of degrees. The inputs are the feature matrix (x), target values (y), \n",
    "# the model function, a list of polynomial degrees, and the number of folds (k).\n",
    "def cross_validation_kfold(x, y, model_function, degrees, k):\n",
    "    # KFold splitter. \n",
    "    # Shuffling the data is crucial here)!\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    results = { degree: [] for degree in degrees }  # Store RMSE for each degree\n",
    "\n",
    "    # Iterate over each polynomial degree\n",
    "    for degree in degrees:\n",
    "        for train_idx, val_idx in kf.split(x):\n",
    "            # Split data into training and validation\n",
    "            x_train, x_val = x[train_idx], x[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            # Train the model on the current k-th fold of data and for the d-th degree polynomial\n",
    "            model = model_function(x_train, y_train, degree)\n",
    "            \n",
    "            # Predict on validation set\n",
    "            y_pred = model.predict(x_val.reshape(-1, 1))\n",
    "            \n",
    "            # Compute RMSE and store\n",
    "            rmse = root_mean_squared_error(y_val, y_pred)\n",
    "            results[degree].append(rmse)\n",
    "    \n",
    "    # Compute average RMSE for each degree\n",
    "    avg_rmse = {degree: np.mean(rmses) for degree, rmses in results.items()}\n",
    "    return avg_rmse\n",
    "\n",
    "# Visualize cross-validation results\n",
    "def plot_validation_results(degrees, avg_rmse):\n",
    "    plt.figure(figsize=(6, 3), dpi=200)\n",
    "    plt.plot(degrees, [avg_rmse[degree] for degree in degrees], \n",
    "             marker=\"o\", linestyle=\"-\", color=colors[0])\n",
    "    plt.xlabel(\"Polynomial degrees\", fontsize=12)\n",
    "    plt.ylabel(\"Avg. RMSE\", fontsize=12)\n",
    "    plt.title(\"K-Fold Cross-Validation\", fontsize=14)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ========== MAIN ==========\n",
    "# Parameters\n",
    "a = +1\n",
    "b = -7\n",
    "c = +3\n",
    "n = 100\n",
    "x_range = (-2.5, 2.5)\n",
    "noise_level = 4.0\n",
    "\n",
    "# Generate data\n",
    "x, y_true, y_noisy = generate_new_data(a, b, c, x_range, n, noise_level)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "avg_rmse = cross_validation_kfold(x, y_noisy, \n",
    "                                  model_function=fit_polynomial_sklearn, \n",
    "                                  degrees=degrees, \n",
    "                                  k=5)\n",
    "\n",
    "# Print average RMSE for each degree\n",
    "for degree, rmse in avg_rmse.items():\n",
    "    print(f\"Degree {degree}: Avg RMSE = {rmse:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plot_validation_results(degrees, avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- After I generated the data in the code section above, why did not I use `train_test_split`? \n",
    "\n",
    "- For the same dataset (same number of sample, noise level, etc.) compare the RMSE results from the `validate_poly_models` function from what you get using `cross_validation_kfold`. Any differences in the RMSE curve? Why?\n",
    "\n",
    "\n",
    "### üí° Reflect and Run\n",
    "I used KFold cross validation (CV) from sklearn. However, you know there are other methods. Apply other CV models in your code and compare their results. For this specific dataset, do you expect differences from different CV models?\n",
    "\n",
    "\n",
    "***\n",
    "# ‚õ∑Ô∏è Exercise\n",
    "\n",
    "The gravitational potential $\\Phi(r, \\theta)$ of a planet is a scalar quantity that describes the gravitational potential energy per unit mass at a point in space. It depends on the radial distance $r$ from the center of the plant and the polar angle $\\theta$ (measured from the planet's axis of symmetry). \n",
    "\n",
    "The general form of the gravitational potential is:\n",
    "\n",
    "$$\n",
    "\\Phi(r, \\theta) = -\\frac{\\mu}{r} \\left( 1 + \\sum_{\\ell=2}^{L} \\frac{J_{\\ell} R_p^\\ell}{r^{\\ell}} P_\\ell(\\cos(\\theta)) \\right),\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mu = G M$ is the standard gravitational parmerter, where $G=6.6743 √ó 10^{-11}\\, \\text{m}^3 \\text{kg}^{-1} \\text{s}^{-2}$ is the gravitational constant and $M$ is the mass of the planet.\n",
    "- $r$ is the radial distance from the center of the planet.\n",
    "- $\\theta$ is the polar angle, typically ranging from 0 (at the north pole) to $\\pi$ (at the south pole).\n",
    "- $R_p$ is the radius of the planet (often the equatorial radius).\n",
    "- $J_{\\ell}$ are the spherical harmonic coefficients that describe the higher-order gravitational moments of the planet, typically used to account for non-spherical mass distributions (such as flattening at the poles or bulging at the equator).\n",
    "- $P_\\ell(\\cos(\\theta))$ are the Legendre polynomials of degree $\\ell$, which depend on the polar angle $\\theta$ and are used to represent the multipole expansion of the gravitational potential.\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Monopole Term**: The first part of the equation, $-\\frac{\\mu}{r}$, represents the gravitional potential for a perfectly spherical planet. This is the **monopole term** and describes the gravitational potential due to the central mass of the planet.\n",
    "   \n",
    "2. **Multipole Terms**: The second part of the equation, $\\sum_{\\ell=2}^{L} ...$, accounts for the non-spherical shape of the planet. It includes terms that describe the **higher-order gravitational moments**, which are important for planets that are not perfect spheres (e.g., planets with equatorial bulges or irregular shapes, which are very common in the solar system. e.g., Earth is not a perfect sphere). These terms are known as **multipole expansions**:\n",
    "    - $\\ell = 2$ corresponds to the **quadropole** moment (flattening of the planet).\n",
    "    - $\\ell = 3$ corresponds to the **octopole** moment, and so on. (I cannot envision the effects for higher terms.)\n",
    "   \n",
    "3. **Legendre Polynomials**: The Legendre polynomials, $P_\\ell[\\cos(\\theta)]$, describe how the potential changes with respect to the polar angle $\\theta$. They ensure that the gravitational potential is consistent with the spherical symmetry of the planet's mass distribution.\n",
    "\n",
    "### Your tasks:\n",
    "\n",
    "A spacecraft has provided measurements for the gravitational potential around a planet with a gravitational parameter $\\mu = 5.793960 \\times 10^{15} \\, \\text{m}^3 \\, \\text{kg}^{-1} \\, \\text{s}^{-2}$. The observed data for the gravitational potential is stored in the file `./datasets/gravitational_potential_data.csv`. \n",
    "\n",
    "#### Steps for Analysis:\n",
    "\n",
    "- **Download and Visualize the Data**: The data includes measurements of the gravitational potential, with the units for each parameter being:\n",
    "   - $r$ (radial distance) in **meters** (m),\n",
    "   - $\\theta$ (polar angle) in **radians** (rad),\n",
    "   - $\\Phi$ (gravitational potential) in **Joules per kilogram** (J/kg).\n",
    "\n",
    "   The dataset contains some measurement noise.\n",
    "\n",
    "- **Important step:** Before processiding any further, read about the Legendre polynomials from: https://en.wikipedia.org/wiki/Legendre_polynomials\n",
    "\n",
    "- **Polynomial Regression**: To model the gravitational potential, we can use a polynomial regression. The goal is to determine the values of the spherical harmonic coefficients $J_2$ and $J_3$, which describe the higher-order gravitational moments. Since the spacecraft could not measure higher-order terms, we limit the expansion to $\\ell = 3$, meaning the maximum order is $J_3$.\n",
    "\n",
    "- **Analysis Goals**:\n",
    "   - **Extract the values** of $J_2$ and $J_3$ from the data using polynomial regression.\n",
    "   - This exercise will be continued in the next lab, using Regularization.\n",
    "\n",
    "***\n",
    "END\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
