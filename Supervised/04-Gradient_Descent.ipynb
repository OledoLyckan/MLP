{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Shahab Fatemi\n",
    "\n",
    "**Email:** shahab.fatemi@umu.se   ;   shahab.fatemi@amitiscode.com\n",
    "\n",
    "**Created:** 2024-11-xx\n",
    "\n",
    "**Last update:** 2025-09-11\n",
    "\n",
    "**MIT License** â€” Shahab Fatemi (2025); For use in the *Machine Learning in Physics* course, UmeÃ¥ University, Sweden; See the full license text in the parent folder.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“¢ <span style=\"color:red\"><strong> Note for Students:</strong></span>\n",
    "\n",
    "* Before working on the labs, review your lecture notes.\n",
    "\n",
    "* Please read all sections, code blocks, and comments **carefully** to fully understand the material. Throughout the labs, my instructions are provided to you in written form, guiding you through the materials step-by-step.\n",
    "\n",
    "* All concepts covered in this lab are part of the course and may be included in the final exam.\n",
    "\n",
    "* I strongly encourage you to work in pairs and discuss your findings, observations, and reasoning with each other.\n",
    "\n",
    "* If something is unclear, don't hesitate to ask.\n",
    "\n",
    "* Exercise submission is not required; these tasks are designed to help you practice, explore the concepts, and learn by doing.\n",
    "\n",
    "* I have done my best to make the lab files as bug-free (and error-free) as possible, but remember: *there is no such thing as bug-free code.* If you observed any bugs, errors, typos, or other issues, I would greatly appreciate it if you report them to me by email. Verbal notifications are not work, as I will likely forget ðŸ™‚\n",
    "\n",
    "ENJOY WORKING ON THIS LAB.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Purpose and Learning Outcomes:\n",
    "\n",
    "In this lab, you will write your own Gradient Descent (GD) algorithm and try it out on different datasets. We will start with the basic version, the Batch GD, and then take a look at how Stochastic GD (SGD) works. You will also see why feature scaling matters by testing an example where the SGD algorithm struggles without scaling.\n",
    "\n",
    "At the end, there is an optional challenge: try using Gradient Descent to solve a physics problem that has nothing to do with machine learning but one can uses GD to find the solution, emphasizing on the importance and global applications of GD.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we begin\n",
    "\n",
    "In all previous notebooks we worked on, we needed to explicitly set the figure size, axis font size, and other parameters to ensure consistent and clear visualizations. To streamline this process, I've created a utility function that automatically configures these settings for you. This function is located in the `./utils/notebook_config.py` file within the parent directory. When these settings are defined in the `notebook_config.py` file, you can simply call the function at the beginning of your notebook to apply them throughout your visualizations. In general, it's a good practice to encapsulate such configurations in a utility function to promote code *reusability* and *maintainability*.\n",
    "You can modify the utility function to customize the default settings according to your preferences, and add or remove any configurations as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../utils'))\n",
    "from notebook_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent (GD)\n",
    "\n",
    "**Overview:** Gradient Descent (GD) is an optimization algorithm used to minimize the cost function. The goal is to find the best-fitting line (or hyperplane) that predicts the output variable based on input features.\n",
    "\n",
    "GD follows these steps:\n",
    "1. *Initialize*: Start with an initial guess for model weights (parameters or coefficients).\n",
    "2. *Compute predictions*: Use current parameters to calculate predicted values.\n",
    "3. *Calculate cost*: Compute the cost using MSE.\n",
    "4. *Compute gradients*: Calculate gradients of the cost function with respect to the parameters.\n",
    "5. *Update parameters*: Adjust parameters in the opposite direction of the gradient using a small learning rate.\n",
    "6. *Iterate*: Repeat until the solution converges or a set number of iterations is reached.\n",
    "\n",
    "In Matrix form for the entire batch\n",
    "$\n",
    "\\mathbf{w}_{new} = \\mathbf{w}_{old} - \\alpha \\frac{2}{n} \\mathbf{x}^\\top (\\mathbf{x} \\mathbf{w}_{old} - \\mathbf{y})\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## â›·ï¸ Exercise\n",
    "\n",
    "In this section, you need to write your own code and apply the concepts you have learned so far by working on a small dataset stored in `../datasets/simple_grad_descent_data1.csv`. Start by loading the dataset from the provided path using pandas. Once the data is loaded, split it into a training and validation sets. \n",
    "\n",
    "After than, analyze and visualize the training set to get an initial sense of the data distribution. Use scatter plots or other relevant visualizations to understand how the input features relate to the target variable.\n",
    "\n",
    "Based on the overview text I provided above and using your lecture notes, develop your own Batch Gradient Descent algorithm for linear regression and track the cost over iterations.\n",
    "\n",
    "Once your implementation is complete, run it on normalized data (later you will see why this is important), and evaluate your model using all relevant metrics; e.g., compute the training error, validation error, visualize the cost function convergence, learning curve, etc. Discuss whether your model appears to underfit, overfit, or generalize well. Use the results of your error metrics and plots to justify your conclusions. Do not spend too much time on the graphics or animating the results. Your focus should be on the correctness of your algorithm implementation, and data analysis.\n",
    "\n",
    "Explore how the learning rate (`alpha`) influence the convergence of the gradient descent algorithm?\n",
    "\n",
    "Now that you made sure your model is implemented correctly, you can apply it to a new dataset stored in `../datasets/simple_grad_descent_data2.csv`. \n",
    "\n",
    "At the very end of this notebook, I've provided the true functions for the developed datasets.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD in sklearn and the effect of Normalization\n",
    "\n",
    "In this section, we use `SGDRegressor` from Scikit-Learn to solve a regression problem using Stochastic Gradient Descent (SGD). First, review your notes on batch, stochastic and mini-batch GD. We build a pipeline that includes optional normalization and polynomial feature expansion.\n",
    "\n",
    "Since SGD is sensitive to feature scaling, we compare runs with and without normalization. You will see that normalization not only improves convergence speed but also reduces sensitivity to the learning rate.\n",
    "\n",
    "Before that, let's generate a simple data including 2 features, x1 and x2, and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples=100, noise_level=5):\n",
    "    np.random.seed(42)\n",
    "    x1 = np.random.uniform(1, 2, num_samples)\n",
    "    x2 = np.random.uniform(1, 2000, num_samples)\n",
    "    y = 4 + 2*x1 - 5*x2\n",
    "    y += np.random.normal(0, noise_level, size=num_samples)  # add some noise\n",
    "    x = np.c_[x1, x2]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate and split data\n",
    "x, y = generate_data(num_samples=200, noise_level=2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot training set\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train, cmap=\"viridis\", edgecolor=\"k\", alpha=0.7)\n",
    "plt.colorbar(label=\"y\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Training data\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, review the `SGDRegressor` manual from:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Run SGD with optional normalization\n",
    "def run_sgd(x, y, normalize, learning_rate, max_iter):\n",
    "    if normalize:\n",
    "        model = make_pipeline( StandardScaler(), # normalize features\n",
    "                SGDRegressor(learning_rate='constant', # force constant learning rate to make results comparable\n",
    "                            eta0=learning_rate, \n",
    "                            max_iter=max_iter, \n",
    "                            tol=1e-9, \n",
    "                            random_state=42) )\n",
    "    else:\n",
    "        model = SGDRegressor(learning_rate='constant', # force constant learning rate to make results comparable\n",
    "                             eta0=learning_rate, \n",
    "                             max_iter=max_iter, \n",
    "                             tol=1e-9, \n",
    "                             random_state=42)\n",
    "    # Fit model\n",
    "    model.fit(x, y)\n",
    "\n",
    "    if normalize:\n",
    "        # Extract weights and bias from the pipeline\n",
    "        # and transform them to original scale\n",
    "        sgdreg  = model.named_steps['sgdregressor']\n",
    "        scaler  = model.named_steps['standardscaler']\n",
    "        scale   = scaler.scale_\n",
    "        mean    = scaler.mean_\n",
    "        weights = sgdreg.coef_ / scale\n",
    "        bias    = sgdreg.intercept_ - np.dot(sgdreg.coef_, mean / scale)\n",
    "    else:\n",
    "        sgdreg  = model\n",
    "        weights = sgdreg.coef_\n",
    "        bias    = sgdreg.intercept_\n",
    "\n",
    "    return bias, weights\n",
    "\n",
    "# Run without normalization\n",
    "bias_no, weights_no = run_sgd(x_train, y_train, normalize=False, learning_rate=1.0e-4, max_iter=10000)\n",
    "print(\"No normalization -> bias, w:\", bias_no, weights_no)\n",
    "\n",
    "# Run with normalization\n",
    "bias_norm, weights_norm = run_sgd(x_train, y_train, normalize=True, learning_rate=1.0e-4, max_iter=10000)\n",
    "print(\"With normalization -> bias, w:\", bias_norm, weights_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### ðŸ’¡ Reflect and Run\n",
    "\n",
    "- What do you observe? Can you change the SGDRegressor hyper-parameters such that the weights without normalization get close to those with normalization?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Finding the ground state of a quantum system\n",
    "\n",
    "If you still have time, let's solve a physics-related optimization problem together. This is not directly related to the Machine Learning, but uses the Gradient Descent method as an optimizer. In case you found errors in my equations and calculations, please correct them and let me know.\n",
    "\n",
    "The ground state, the state of a system with the lowest possible energy allowed by quantum mechanics, corresponds to the eigenstate of the Hamiltonian operator ($\\hat{H}$) with the lowest eigenvalue (energy) such that \n",
    "$$\n",
    "\\hat{H}\\psi_0â€‹ = E_0 \\psi_0\n",
    "$$\n",
    "\n",
    "The trial wave function, representing a Gaussian wavefunction, is defined as\n",
    "$$\n",
    "\\psi(x,\\alpha)=e^{âˆ’\\alpha x^2}\n",
    "$$\n",
    "\n",
    "The Hamiltonian operator ($\\hat{H}$) is defined as $\\hat{T} + \\hat{V}$, where $\\hat{T}$ is the kinetic energy operator, and $\\hat{V}$ is the potential energy operator (harmonic oscillator potential).\n",
    "\n",
    "The second derivative of the wavefunction is approximated using the finite-difference method:\n",
    "$$\n",
    "\\frac{\\partial^2 \\psi(x)}{\\partial x^2} \\approx \\frac{\\psi(x + \\Delta x) - 2\\psi(x) + \\psi(x - \\Delta x)}{\\Delta x^2}\n",
    "$$\n",
    "\n",
    "Assuming $\\hbar=m=1$, then\n",
    "\n",
    "$$\n",
    "T = -\\frac{1}{2} \\frac{\\partial^2 \\psi(x)}{\\partial x^2} \\\\\n",
    "V = \\frac{1}{2} \\omega^2 x^2 \\psi(x)\n",
    "$$\n",
    "\n",
    "The total Hamiltonian acting on the wavefunction becomes $\\hat{H}\\psi(x)=T(x)+V(x)$, and the expectation value of the Hamiltonian in discretized form (with normalization included) is\n",
    "$$\n",
    "\\langle H \\rangle = \\frac{\\sum_i \\psi^*(x_i) \\hat{H} \\psi(x_i) \\Delta x}{\\sum_i |\\psi(x_i)|^2 \\Delta x}\n",
    "$$\n",
    "\n",
    "To optimize $\\alpha$ (the variational parameter), we can minimize energy using gradient descent. The gradient of the energy with respect to $\\alpha$ is approximated using the central difference method,\n",
    "$$\n",
    "\\frac{\\partial \\langle H \\rangle}{\\partial \\alpha} \\approx \\frac{\\langle H \\rangle(\\alpha + \\delta \\alpha) - \\langle H \\rangle(\\alpha - \\delta \\alpha)}{2 \\delta \\alpha}\n",
    "$$\n",
    "\n",
    "The variational parameter $\\alpha$ is updated iteratively using the gradient descent algorithm. The update rule is given by:\n",
    "$$\n",
    "\\alpha_{n+1} = \\alpha_n - \\eta \\cdot \\frac{\\partial \\langle H \\rangle}{\\partial \\alpha}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (in atomic units)\n",
    "m     = 1.0     # Mass\n",
    "omega = 1.0     # Angular frequency\n",
    "dx    = 0.1     # Discretization step size\n",
    "x_min = -1.0    # Min range of x\n",
    "x_max = +1.0    # Max range of x\n",
    "num_points = int((x_max - x_min) / dx)      # Number of grid points\n",
    "x = np.linspace(x_min, x_max, num_points)  # Spatial grid\n",
    "\n",
    "# Trial wavefunction (Gaussian form)\n",
    "# x is the position variable\n",
    "# alpha is the variational parameter for the wavefunction\n",
    "def wavefunction(x, alpha):\n",
    "    return np.exp(-alpha * x**2)\n",
    "\n",
    "# Hamiltonian operator applied to the wavefunction.\n",
    "def hamiltonian(x, alpha):\n",
    "    # Compute the second derivative (discretized)\n",
    "    psi = wavefunction(x, alpha)\n",
    "    d2dx2 = (np.roll(psi, -1) - 2 * psi + np.roll(psi, 1)) / dx**2\n",
    "    \n",
    "    # Kinetic energy term\n",
    "    T = -0.5 * d2dx2\n",
    "    \n",
    "    # Potential energy temr\n",
    "    V = 0.5 * m * (omega**2) * (x**2) * psi\n",
    "    \n",
    "    return (T + V)\n",
    "\n",
    "# Compute the expectation value of the Hamiltonian.\n",
    "def expectation_value(x, alpha):\n",
    "    psi  = wavefunction(x, alpha)\n",
    "    Hpsi = hamiltonian (x, alpha)\n",
    "    \n",
    "    # Numerically integrate the expectation value (normalization included)\n",
    "    numerator = np.sum(np.conj(psi) * Hpsi) * dx\n",
    "    denominator = np.sum(np.abs(psi)**2) * dx\n",
    "    \n",
    "    return (numerator/denominator)\n",
    "\n",
    "# Compute the numerical gradient of the expectation value w.r.t. alpha.\n",
    "def gradient(x, alpha, epsilon=1.0e-6):\n",
    "    E_plus  = expectation_value(x, alpha + epsilon)\n",
    "    E_minus = expectation_value(x, alpha - epsilon)\n",
    "    return (E_plus - E_minus) / (2 * epsilon)\n",
    "\n",
    "# Perform gradient descent to minimize the expectation value and find the ground state.\n",
    "def gradient_descent(x, alpha_init, learning_rate=0.01, iterations=100):\n",
    "    alpha = alpha_init\n",
    "    alpha_history  = [alpha]\n",
    "    energy_history = []\n",
    "    \n",
    "    for iter in range(iterations):\n",
    "        energy = expectation_value(x, alpha)\n",
    "        energy_history.append(energy)\n",
    "        \n",
    "        # Calculate the gradient and update alpha\n",
    "        grad   = gradient(x, alpha)\n",
    "        alpha -= learning_rate * grad\n",
    "        \n",
    "        alpha_history.append(alpha)\n",
    "    \n",
    "    return alpha, energy_history, alpha_history\n",
    "\n",
    "def plot_hamilton_results(energy_history, alpha_history):\n",
    "    plt.figure(figsize=(6, 3)) \n",
    "    \n",
    "    # Plot energy history\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(energy_history, label=\"Energy History\", lw=1, color=\"royalblue\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Energy\")\n",
    "    plt.title(\"Energy Convergence\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot alpha history\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(alpha_history, label=\"Alpha History\", lw=1, color=\"forestgreen\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Alpha\")\n",
    "    plt.title(\"Alpha Convergence\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Main code to find the ground state\n",
    "alpha_init    = 1.0  # Initial guess for alpha\n",
    "learning_rate = 0.05\n",
    "iterations    = 200  # Number of iterations for gradient descent\n",
    "\n",
    "# Perform gradient descent to minimize the energy\n",
    "alpha_opt, energy_history, alpha_history = gradient_descent(x, alpha_init, learning_rate, iterations)\n",
    "\n",
    "# optimized variational parameter and the final energy\n",
    "print(f\"Optimized alpha: {alpha_opt}\")\n",
    "print(f\"Final energy: {energy_history[-1]}\")\n",
    "\n",
    "# Plot the results\n",
    "plot_hamilton_results(energy_history, alpha_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ðŸ“ˆ Solution\n",
    "For the data stored in `../datasets/simple_grad_descent_data1.csv`, I used $f(x)=3x^4-6x^3-2$ and for the data stored in `../datasets/simple_grad_descent_data2.csv`, $f(x)=5/((x-1.5)^2+1)$.\n",
    "\n",
    "***\n",
    "END\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
