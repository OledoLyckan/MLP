{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d0f5f9",
   "metadata": {},
   "source": [
    "**Author:** Shahab Fatemi\n",
    "\n",
    "**Email:** shahab.fatemi@umu.se   ;   shahab.fatemi@amitiscode.com\n",
    "\n",
    "**Created:** 2024-11-10\n",
    "\n",
    "**Last update:** 2025-09-14\n",
    "\n",
    "**MIT License** ‚Äî Shahab Fatemi (2025); For use in the *Machine Learning in Physics* course, Ume√• University, Sweden; See the full license text in the parent folder.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a8df2",
   "metadata": {},
   "source": [
    "üì¢ <span style=\"color:red\"><strong> Note for Students:</strong></span>\n",
    "\n",
    "* Before working on the labs, review your lecture notes.\n",
    "\n",
    "* Please read all sections, code blocks, and comments **carefully** to fully understand the material. Throughout the labs, my instructions are provided to you in written form, guiding you through the materials step-by-step.\n",
    "\n",
    "* All concepts covered in this lab are part of the course and may be included in the final exam.\n",
    "\n",
    "* I strongly encourage you to work in pairs and discuss your findings, observations, and reasoning with each other.\n",
    "\n",
    "* If something is unclear, don't hesitate to ask.\n",
    "\n",
    "* Exercise submission is not required; these tasks are designed to help you practice, explore the concepts, and learn by doing.\n",
    "\n",
    "* I have done my best to make the lab files as bug-free (and error-free) as possible, but remember: *there is no such thing as bug-free code.* If you observed any bugs, errors, typos, or other issues, I would greatly appreciate it if you report them to me by email. Verbal notifications are not work, as I will likely forget üôÇ\n",
    "\n",
    "ENJOY WORKING ON THIS LAB.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d247cb6",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Purpose and Learning Outcomes:\n",
    "\n",
    "The main focus of this lab is binary classification, using two fundamental methods:\n",
    "  - Perceptron\n",
    "  - Logistic Regression\n",
    "\n",
    "You will also learn about the confusion matrix, a key tool for evaluating classification accuracy and precision.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb219426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../utils'))\n",
    "from notebook_config import *\n",
    "\n",
    "# Creating a list of colors based on the \"tab10\" colormap.\n",
    "# I like the color set in the \"tab10\" colormap.\n",
    "cmap = plt.colormaps[\"tab10\"]\n",
    "colors = [cmap(i) for i in range(21)]\n",
    "\n",
    "# Different Marker for Scatter plot\n",
    "markers = ['o', 's', '*', 'x', '^', 'v', '<', '>']  # Different markers for different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b7ea9",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "\n",
    "**Overview:** Binary classification aims to categorize (classifies) input data into one of two distinct categories (or classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a62c96",
   "metadata": {},
   "source": [
    "In the code section below, I've defined different functions to generate datasets with different geometric patterns and separations for classification. They provide samples of both linearly and non-linearly separable data. Based on our needs, we are going to call these functions in this notebook, because WE NEED DATA. You will see, in the upcoming code-section, the outcome of each function. So for now, quickly read what each function does and then run the code below. There should be no outputs, and it should run with no error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4060f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_circles, make_moons, make_blobs\n",
    "\n",
    "# This function uses sklearn \"make_classification\" to generate a dataset with \n",
    "# two informative features, and one cluster per class.\n",
    "# I've intentionally used a non-42 rand state here! Do not change it!\n",
    "def make_regular_data(n_samples=500, rand_state=90):\n",
    "    x, y = make_classification(n_samples=n_samples, n_features=2, n_redundant=0,\n",
    "                               n_informative=2, n_clusters_per_class=1, random_state=rand_state)\n",
    "    return x, y\n",
    "\n",
    "# This function creates points uniformly distributed in a square and \n",
    "# labels them based on whether they lie above or below the line y = x, \n",
    "# producing a simple linear decision boundary.\n",
    "def make_diagonal_data(n_samples=500, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Generate uniform data in range [0, 5]\n",
    "    x = np.random.uniform(0, 5, size=(n_samples, 2))\n",
    "\n",
    "    # true labels based on y > x\n",
    "    y = (x[:, 1] > x[:, 0]).astype(int)\n",
    "    return x, y\n",
    "\n",
    "# This function generates a dataset with a non-linear XOR pattern such that points are labeled \n",
    "# as class 1 if exactly one of their coordinates is greater than 2.5, and class 0 otherwise. \n",
    "# This creates a checkerboard-like separation.\n",
    "def make_xor_data(n_samples=500, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Generate uniform data in range [0, 5]\n",
    "    x = np.random.uniform(0, 5, size=(n_samples, 2))\n",
    "\n",
    "    # XOR condition: label is 1 if one of the coordinates is >2.5 and the other is <=2.5\n",
    "    y = (((x[:, 0] >  2.5) & (x[:, 1] <= 2.5)) | \n",
    "         ((x[:, 0] <= 2.5) & (x[:, 1] >  2.5))).astype(int)\n",
    "    return x, y\n",
    "\n",
    "# This function produces a dataset consisting of two noisy concentric circles: \n",
    "# an inner and outer ring are labeled as different classes. \n",
    "# This is a classic example of a non-linearly separable dataset, useful for testing non-linear classifiers.\n",
    "def make_concentric_circles(n_samples=500, factor=0.3, noise=0.1):\n",
    "    x, y = make_circles(n_samples=n_samples, factor=factor, noise=noise, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "# Similar to the circle function, this function makes two interleaving half circles.\n",
    "def make_two_half_moons(n_samples=500, noise=0.2):\n",
    "    x, y = make_moons(n_samples=n_samples, noise=noise, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "# This function generates a dataset with three distinct clusters using Gaussian blobs.\n",
    "def make_three_classes(n_samples=500, noise=0.7):\n",
    "    x, y = make_blobs(n_samples=n_samples,\n",
    "                    centers=[[0, 5], [2, 0], [5, 4]], #[[0, 5], [2, 0], [5, 4], [2, 6]],\n",
    "                    cluster_std=noise,\n",
    "                    random_state=42)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8cd3a",
   "metadata": {},
   "source": [
    "Let's:\n",
    "1. Generate data using a few data generators above,\n",
    "2. Split the data into training and validation sets, and\n",
    "3. Visualize the training data to understand its structure.\n",
    "\n",
    "These are the standard first steps in any machine learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data visualization function\n",
    "def visualize_data(x, y, title):\n",
    "    plt.figure()\n",
    "    \n",
    "    classes = np.unique(y) # Get unique class labels\n",
    "\n",
    "    for i, label in enumerate(classes):\n",
    "        plt.scatter(\n",
    "            x[y == label, 0],\n",
    "            x[y == label, 1],\n",
    "            marker=markers[i % len(markers)],\n",
    "            color=colors[i], edgecolor=\"k\" ,\n",
    "            s=50, alpha=0.7, \n",
    "            label=f\"Class {label}\")\n",
    "\n",
    "    plt.xlabel(\"Feature 1 (x1)\")\n",
    "    plt.ylabel(\"Feature 2 (x2)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806992b6",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Data splitting\n",
    "Note that you need to split data into training and validation (test) sets before performing analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = make_regular_data()\n",
    "\n",
    "# Since the data is sparse, I make a larger validation set (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "visualize_data(X_train, y_train, \"Regular Data (Training Set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_concentric_circles()\n",
    "\n",
    "# Since the data is sparse, I make a larger validation set (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "visualize_data(X_train, y_train, \"Concentric Circles Data (Training Set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f0ca3",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- What does \"stratified split\" mean in the `train_test_split` function used above, and why is the split based on the \"y\" values? (e.g., see line 7 in the previous code block.)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f6e20",
   "metadata": {},
   "source": [
    "## üîó Perceptron Learning\n",
    "\n",
    "(I assume you have already implemented your Perceptron algorithm, as previously recommended and emphasized in the class.)\n",
    "\n",
    "**Overview:** Here, we develop a **perceptron** classifier from scratch and apply it to various datasets to explore how a simple linear model learns to separate different classes over time. Some of our generated datasets from the previous code section are linear functions, while some others are non-linear. The perceptron model developed here is not applicable to the non-linear data.\n",
    "\n",
    "### Development\n",
    "\n",
    "The perceptron is trained using data generated by our datasets with labels (y) converted to $y \\in \\{-1, 1\\}$ to align with the original algorithm's formulation. During training, the perceptron iteratively adjusts its weights and bias whenever it misclassifies a sample. Over multiple epochs, the model learns how to find a separating hyperplane.\n",
    "\n",
    "The perceptron makes predictions using this rule: $y^* = \\text{sign}(\\mathbf{w} \\cdot \\mathbf{x} + b)$\n",
    "\n",
    "This is exactly what the `predict` function implements in the class below. In the code section below, find the `predic` function and compare its implementation with the mathematical formula above. They should match.\n",
    "\n",
    "In addition to the `preduct`, I've another function named `train`. This is what the `train` does:\n",
    "- If the prediction is **correct**, no change is made.  \n",
    "- If the prediction is **incorrect**, the weights need to be updated to shift the decision boundary in the *right* direction. \n",
    "\n",
    "The update rule that adjusts the weights in the *right* direction is given by $\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} + \\eta (y - y^*) \\mathbf{x}$ where $\\eta$ is the learning rate (also see lecture notes).\n",
    "\n",
    "What I've explained above is directly implimented in the `train` function. Additionally, the `train` function stores wights and bias at each epoch together with the *misclassification percentage* at each epoch for later analysis.\n",
    "\n",
    "Now that you have done these pre-studies, understanding the code below is simple, because the remaining functions are used to visualize the results. You should also compare the above explanation with the Perceptron Algorithm I explained in the class.\n",
    "\n",
    "‚ö†Ô∏è NOTE: The model we have developed below is an iterative model, and therefore, it needs to start with pre-defined values for the Weights ($\\mathbf{w}$) and Bias (${w_0}$). Over different iterations, the model will update the Weights and Biases to find the most optimal solution (i.e., minimizing the error). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40630f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Simple Perceptron Class for binary classification\n",
    "class SimplePerceptron:\n",
    "    # Initialize the perceptron with training data and hyper-parameters\n",
    "    def __init__(self, x, y, eta=0.1, epochs=20):\n",
    "        self.x       = x        # Input features\n",
    "        self.y       = y        # Target labels\n",
    "        \n",
    "        self.eta     = eta      # Learning rate\n",
    "        self.epochs  = epochs   # Number of epochs\n",
    "        \n",
    "        self.w       = np.zeros(x.shape[1])  # Initial Weights (these are required for the iterative approach to begin with)\n",
    "        self.b       = 0        # Initial Bias (these are required for the iterative approach to begin with)\n",
    "\n",
    "        # Housekeeping data for tracking and further analysis\n",
    "        self.coeff_hist  = []       # History of model coefficients (Weight and Bias) over epochs\n",
    "        self.mis_percent = []       # Percentage of mis-classified samples over epochs\n",
    "\n",
    "    # This function makes a prediction for input x using the linear \n",
    "    #   decision rule, explained in the markdown cell above.\n",
    "    def predict(self, x):\n",
    "        return np.where(np.dot(x, self.w) + self.b >= 0, +1, -1)\n",
    "\n",
    "    # This function trains a simple linear classifier using perceptron algorithm over several iterations. \n",
    "    # For each training example, it updates the model's weights and bias if the prediction is incorrect. \n",
    "    # It also stores a history for Weight and Bias as well as the errors over epochs.\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            mis_count = 0 # Count misclassifications\n",
    "            for x_i, y_i in zip(self.x, self.y):  # Iterate over every training example (x_i, y_i)\n",
    "                y_star = self.predict(x_i)        # Predict the label y^*\n",
    "                update = self.eta * (y_i - y_star)\n",
    "                if(update != 0):     # If the prediction is incorrect\n",
    "                    mis_count += 1   # Increment the misclassification counter\n",
    "                self.w += update * x_i  # Update weights\n",
    "                self.b += update        # Update bias\n",
    "            self.coeff_hist.append((self.w.copy(), self.b)) # Store the history of weights and bias\n",
    "            self.mis_percent.append(mis_count*100/self.y.shape[0]) # Calculate misclassification percentage and keep its history\n",
    "            \n",
    "            # Visualize decision boundary for current epoch\n",
    "            self.plot_decision_boundary(epoch)\n",
    "\n",
    "    # Visualize data and decision boundary for the given epoch\n",
    "    def plot_decision_boundary(self, epoch):\n",
    "        clear_output(wait=True)\n",
    "        plt.figure()\n",
    "\n",
    "        classes = np.unique(self.y) # Get unique class labels\n",
    "\n",
    "        # Plot training data\n",
    "        for i, label in enumerate(classes):\n",
    "            plt.scatter(\n",
    "                self.x[self.y == label, 0],\n",
    "                self.x[self.y == label, 1],\n",
    "                marker=markers[i % len(markers)],\n",
    "                color=colors[i], edgecolor=\"k\" ,\n",
    "                s=50, alpha=0.7, \n",
    "                label=f\"Class {label}\")\n",
    "\n",
    "        # plot decision boundaries\n",
    "        x_vals = np.linspace(self.x[:, 0].min() - 1, self.x[:, 0].max() + 1, 200)\n",
    "        for i, (w, b) in enumerate(self.coeff_hist):\n",
    "            if(w[1] == 0):\n",
    "                continue\n",
    "            y_vals = -(w[0] * x_vals + b) / w[1] # Decision boundary equation\n",
    "            intensity = (i + 1) / self.epochs    # Calculate intensity for color mapping\n",
    "            color = (1 - intensity, 1 - intensity, 1 - intensity) # Grayscale color mapping\n",
    "            plt.plot(x_vals, y_vals, color=color, linewidth=2.0, alpha=0.8)\n",
    "        \n",
    "        plt.xlabel('Feature 1 (x1)')\n",
    "        plt.ylabel('Feature 2 (x2)')\n",
    "        plt.title(f'Perceptron Learning (Epoch {epoch + 1})')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    # plot misclassifications\n",
    "    def plot_misclassified_history(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, self.epochs + 1), self.mis_percent, marker='o', color='forestgreen', linewidth=2, alpha=0.7)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Errors (%)')\n",
    "        plt.title('Misclassifications history')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_weights_bias_history(self):\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, self.epochs + 1), [wb[0][0] for wb in self.coeff_hist], \"-\", color=colors[0], linewidth=2, label=\"w1\")\n",
    "        plt.plot(range(1, self.epochs + 1), [wb[0][1] for wb in self.coeff_hist], \"-\", color=colors[1], linewidth=2, label=\"w2\")\n",
    "        plt.plot(range(1, self.epochs + 1), [wb[1] for wb in self.coeff_hist]   , \"-\", color=colors[2], linewidth=2, label=\"bias (w0)\")\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Weights and Bias history')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "# ========== MAIN ==========\n",
    "# Generate data\n",
    "x, y = make_regular_data()\n",
    "# x, y = make_diagonal_data()\n",
    "# x, y = make_xor_data()\n",
    "# x, y = make_concentric_circles()\n",
    "y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1\n",
    "\n",
    "# Since the data is sparse, I make a larger validation set (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Run the Simple Perceptron\n",
    "perceptron = SimplePerceptron(X_train, y_train, eta=0.1, epochs=20)\n",
    "perceptron.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab83e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model coefficients:\", perceptron.w)\n",
    "print(\"Bias (w0):\", perceptron.b)\n",
    "print(rf'Decision Boundary: {perceptron.w[0]:+.2f} x_1 {perceptron.w[1]:+.2f} x_2 {perceptron.b:+.2f} = 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d7380",
   "metadata": {},
   "source": [
    "Now we want to visualize the misclassification history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to visualize the misclassification history\n",
    "perceptron.plot_misclassified_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32512397",
   "metadata": {},
   "source": [
    "And then, we want to plot the evolution of weights and bias over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the evolution of weights and bias over epochs\n",
    "perceptron.plot_weights_bias_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136b6b6",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- Why is $y \\in {-1, +1}$ used for the Perceptron algorithm? Is this requirement essential?\n",
    "\n",
    "- After running the code for 20 iterations, do you think the Perceptron has converged to a final solution?\n",
    "\n",
    "- What exactly is shown in the miscladsification figure? Which type of error does it represent?\n",
    "\n",
    "- Why doesn't the misclassification error reach zero? Would you expect it to reach zero if the number of epochs is increased? Try running the algorithm for more epochs. What do you observe, and why?\n",
    "\n",
    "- How does the misclassification rate change over the epochs, and what can you conclude from the figure? Does your conclusion align with the weight and bias history plot?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe72ea",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "Let's evaluate our model with evaluation metrics. First, we look at the confusion matrix (or contingency matrix). A confusion matrix is a simple table used to evaluate how well a classification model performs. It compares the model's predictions with the actual outcomes and shows where the model was correct or made mistakes. This breakdown helps identify specific areas for improvement. \n",
    "The confusion matrix has four key categories:\n",
    "- True Positive (TP): The model correctly predicted a positive outcome (and the actual outcome was positive).\n",
    "- True Negative (TN): The model correctly predicted a negative outcome (and the actual outcome was negative).\n",
    "- False Positive (FP): The model incorrectly predicted a positive outcome (the actual outcome was negative). This is also called a Type I error.\n",
    "- False Negative (FN): The model incorrectly predicted a negative outcome (the actual outcome was positive). This is also called a Type II error.\n",
    "\n",
    "Here is an example of a confusion matrix:\n",
    "|                          | **Predicted Positive** | **Predicted Negative** |\n",
    "|--------------------------|------------------------|------------------------|\n",
    "| **Actual Positive**      | True Positive (TP)     | False Negative (FN)    |\n",
    "| **Actual Negative**      | False Positive (FP)    | True Negative (TN)     |\n",
    "\n",
    "\n",
    "‚ö†Ô∏è NOTE: All evaluation metrics need to be performed on the validation (or test) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions on validation data\n",
    "y_pred = perceptron.predict(X_val)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "labels = [\"Class -1\", \"Class +1\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=labels, yticklabels=labels,\n",
    "            cbar=False, linewidths=1, linecolor=\"black\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc33635",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- What do you see from the Confusion Matrix and what does it tell us about the model performance?\n",
    "\n",
    "### üí° Reflect and Run\n",
    "\n",
    "- Increase the number of epochs from 20 to 100 and run the training again. I recommend opening a new code cell and writing all necessary code there, without modifying the earlier cells. This is because you will need the results from the previous run for comparison. After training the new model, check if it converges to a solution with more iterations. Then, perform a full model evaluation using performance metrics (here, the confusion matrix), and compare your results with those from the earlier model.\n",
    "\n",
    "- Now generate data using `make_diagonal_data()` and run your code again. What do you observe?\n",
    "\n",
    "- Now try `make_xor_data()` or `make_concentric_circles()` to generate data and run your code. What do you observe and what does the confusion matrix tell you about the model? Remeber, these functions are non-linear, while our developed Perceptron works on **linear** data.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf8a22",
   "metadata": {},
   "source": [
    "## Perceptron from sklearn\n",
    "\n",
    "In addition to implementing our own perceptron from scratch, you can also use `sklearn.linear_model.Perceptron`, which provides efficient implementation of the perceptron algorithm with some additional features like regularization, and early stopping. We can use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7313d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "x, y = make_regular_data()\n",
    "y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1\n",
    "\n",
    "# Since the data is sparse, I make a larger validation set (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Create a Perceptron classification model\n",
    "clf_model = Perceptron(max_iter=20, eta0=0.1)\n",
    "\n",
    "# Train the model\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the weights and bias\n",
    "w = clf_model.coef_\n",
    "b = clf_model.intercept_\n",
    "print(\"Model coefficients:\", w)\n",
    "print(\"Bias (w0):\", b)  \n",
    "print(rf'Decision Boundary: {w[0,0]:+.2f} x_1 {w[0,1]:+.2f} x_2 {b[0]:+.2f} = 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9675f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf_model.predict(X_val)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "labels = [\"Class -1\", \"Class +1\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=labels, yticklabels=labels,\n",
    "            cbar=False, linewidths=1, linecolor=\"black\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0b09b",
   "metadata": {},
   "source": [
    "Compare the decision boundary and the confusion matrix you got from sklearn with those you got earlier from my implementation. Any difference? ü§ì\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c1a13",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Overview:** Logistic regression is a statistical method for binary classification. Unlike linear models like the perceptron, which produce hard binary outputs (e.g., 0 or 1, or ‚Äì1 or +1) based on a step function applied to the weighted sum of inputs, logistic regression uses the sigmoid (logistic) function to produce a smooth probabilisitc output between 0 and 1. \n",
    "\n",
    "In the code below, we train our regular binary dataset using logistic regression, implemented in scikit-learn. The model learns a linear decision boundary by fitting the data to a sigmoid function.\n",
    "\n",
    "‚ö†Ô∏è NOTE: The sigmoid function produces values between 0 and 1 (do you know why?), and therefore, unlike previous sections, we do not need to convert our labels to -1 and +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# This is our regular data.\n",
    "x, y = make_regular_data()\n",
    "\n",
    "## This line is commented out, and is not needed.\n",
    "# y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1\n",
    "\n",
    "# Since the data is sparse, I make a larger validation set (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# print the weights or model coefficients from the classifier\n",
    "w = lr_model.coef_\n",
    "b = lr_model.intercept_\n",
    "print(\"Model coefficients:\", w)\n",
    "print(\"Intercept (w0):\", b)\n",
    "print(rf'Decision Boundary: {w[0,0]:+.2f} x_1 {w[0,1]:+.2f} x_2 {b[0]:+.2f} = 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513f025",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- Compare the decision boundary obtained from logistic regression with the one learned by the perceptron (both my implementation and the one from sklearn). Are the boundaries similar in shape and orientation? Do they separate the classes in the same way? Should they be similar or not?\n",
    "\n",
    "- Use the model coefficients and intercept values to theoretically calculate $P(y=1|(x_1=-0.5, x_2=0.0))$. What does that value mean? See your lecture notes on how to calculate $P$.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ec69d",
   "metadata": {},
   "source": [
    "Let's visualize the decision boundary. I have written a function that plots the data and creates a mesh grid covering the input space. For each point on the grid, the trained model predicts the probability of the positive class. These probabilities are visualized using a heatmap. The decision boundary (at 0.5) is highlighted. Additional contour lines at levels like 10%, 30%, 70%, and 90% are also shown to illustrate how the model's confidence varies across the space. \n",
    "\n",
    "Since I will be using the visaulization function for both probabilistic and non-problabilistic models, I have added a control parameter to enable or disable probability-based visualizations. This allows the same function to handle models that output class probabilities (like logistic regression) as well as those that don't (like the perceptron)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary_decision(x, y, model, probabilistic=True):\n",
    "    plt.figure()\n",
    "\n",
    "    classes = np.unique(y)   # Get unique class labels\n",
    "    n_classes = len(classes)  # Number of classes\n",
    "\n",
    "    # Plot the data points\n",
    "    for i, label in enumerate(classes):\n",
    "        plt.scatter( x[y == label, 0],\n",
    "                    x[y == label, 1],\n",
    "                    marker=markers[i % len(markers)],\n",
    "                    color=colors[i], edgecolor=\"k\",\n",
    "                    s=50, alpha=0.7,\n",
    "                    label=f\"Class {label}\" )\n",
    "\n",
    "    # create a 100x100 mesh grid for maping the decision boundary on it\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x[:, 0].min() - 0.5, x[:, 0].max() + 0.5, 100),\n",
    "        np.linspace(x[:, 1].min() - 0.5, x[:, 1].max() + 0.5, 100) )\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    if probabilistic:\n",
    "        probs = model.predict_proba(grid)  # shape: (num_points, n_classes)\n",
    "        if probs.shape[1] == 2:\n",
    "            # Binary classification take the positive class probability\n",
    "            probs_display = probs[:, 1].reshape(xx.shape)\n",
    "        else:\n",
    "            # Multiclass: take max probability as \"confidence\" for current decision\n",
    "            probs_display = np.max(probs, axis=1).reshape(xx.shape)\n",
    "    else:\n",
    "        preds = model.predict(grid)\n",
    "        probs_display = preds.reshape(xx.shape)\n",
    "\n",
    "    # Plot contour lines\n",
    "    if probabilistic:\n",
    "        prob_levels = [0.1, 0.3, 0.7, 0.9]\n",
    "    else:\n",
    "        prob_levels = [0.5]\n",
    "\n",
    "    for p in prob_levels:\n",
    "        contour = plt.contour(xx, yy, probs_display, levels=[p], linestyles=\"--\", linewidths=1.0)\n",
    "        plt.clabel(contour, fmt={p: f'{int(p * 100)}%'})\n",
    "\n",
    "    # Plot decision boundary (0.5 level or class change)\n",
    "    if probabilistic:\n",
    "        plt.contour(xx, yy, probs_display, levels=[0.5], colors='k', linewidths=2)\n",
    "    else:\n",
    "        plt.contour(xx, yy, probs_display, levels=np.arange(n_classes + 1) - 0.5, colors='k', linewidths=2)\n",
    "\n",
    "    # Heatmap background\n",
    "    plt.contourf(xx, yy, probs_display, levels=100, cmap=\"coolwarm\", alpha=0.3)\n",
    "\n",
    "    plt.xlabel(\"Feature 1 (x1)\")\n",
    "    plt.ylabel(\"Feature 2 (x2)\")\n",
    "    plt.title(\"Decision Boundary\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## ========== MAIN ==========\n",
    "plot_boundary_decision(X_train, y_train, lr_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9b349",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- Study the figure above. Where is the decision boundary and what are those solid and dashed lines?\n",
    "\n",
    "- Locate the point $x_1=-0.5, x_2=0.0$ on the decision boundary plot. Compare the predicted probability $P$ you previously calculated at this point using the logistic regression model with the color and contour value shown in the figure.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a605fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_val)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "labels = [\"Class -1\", \"Class +1\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=labels, yticklabels=labels,\n",
    "            cbar=False, linewidths=1, linecolor=\"black\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f9837c",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "- Compare the confusion matrix obtained from logistic regression with the one learned by the perceptron (both my implementation and the one from sklearn). Why is the one from logisitic regression different?\n",
    "\n",
    "### üí° Reflect and Run\n",
    "- Read more about `LogisticRegression()` from the [official scikit-learn website](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to understand the available options for regularization in Logisitic Regression. Modify your code to use both **L1** (Lasso) and **L2** (Ridge) regularization by setting the appropriate values for the `penalty`, `solver`, and `C` parameters. Train the logistic regression model separately with each regularization and compare the results with those you got earlier using the default settings. Discuss how regularization influences the model and under what conditions one might be preferred over the other.\n",
    "\n",
    "- To generate a new data, use\n",
    "```python\n",
    "    x, y = make_regular_data( rand_state=870 )\n",
    "```\n",
    "visualize the data and test your model and its performance.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c037f0",
   "metadata": {},
   "source": [
    "## Non-Linear Classification with Polynomial Perceptron\n",
    "\n",
    "Let's move back to the `Perceptron` again. This time, we want to apply it to a non-linear classification problem. Wait, what? Yes, to a non-linear problem, and it works, similar to the closed-form solution we applied to polynomial functions. Let's figure it out.\n",
    "\n",
    "The code below defines a custom classifier that combines polynomial feature expansion with a perceptron to handle non-linear classification tasks. By transforming input data into a higher-dimensional polynomial space, we allow the linear perceptron to learn complex decision boundaries ü§ì. The model is trained and evaluated using a pipeline, with data  Standardizeation. \n",
    "\n",
    "Here, we use the `Perceptron` function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load or generate your data\n",
    "x, y = make_regular_data()\n",
    "y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Create pipeline: standardize, polynomial transform, and then perceptron\n",
    "poly_perc_model = make_pipeline( StandardScaler(),  # Standardize features\n",
    "                        PolynomialFeatures(degree=2),   # You can change degree to 3, 4, etc.\n",
    "                        Perceptron(max_iter=100, eta0=1.0, random_state=42) )\n",
    "\n",
    "# Train\n",
    "poly_perc_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the trained perceptron model (last step in the pipeline)\n",
    "perc = poly_perc_model[-1]\n",
    "\n",
    "# Print coefficients and intercept\n",
    "print(\"Coefficients:\", perc.coef_)\n",
    "print(\"Intercept:   \", perc.intercept_)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_boundary_decision(X_train, y_train, poly_perc_model, probabilistic=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fc680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracy for train and test datasets\n",
    "print(\"Train accuracy:\", poly_perc_model.score(X_train, y_train))\n",
    "print(\"Validation accuracy:\", poly_perc_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fdc9b",
   "metadata": {},
   "source": [
    "***\n",
    "### üí° Reflect and Run\n",
    "\n",
    "- Carefully study the code above and make sure you understand how the pipeline works. Then, modify the polynomial degree from 2 to 3, 5, 7, and higher. Observe how the decision boundary changes as the degree increases. Does the model start to overfit?\n",
    "\n",
    "- For each polynomial degree, plot the confusion matrix and compare the results. What patterns or trends do you notice across degrees? Are there any similarities in classification performance? Reflect on the trade-off between model complexity and generalization.\n",
    "\n",
    "- Now you can apply the pipeline to the non-linear datasets we generated earlier: try `make_concentric_circles` and `make_two_half_moons` and test it for low- and high-order polynomials.\n",
    "\n",
    "- Let's do something even more cool! Simply replace the `Perceptron` line in the pipeline with the `LogisticRegression()` and re-run the code for different datasets, different polynomial degrees, with and without L1 and L2 regularizations, and find the best model. Do not forget to set `probabilistic=True` when you call `plot_boundary_decision` function. What you seeing is the beauty of scikit-learn and its powerful pipeline.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc04e2",
   "metadata": {},
   "source": [
    "## Multiclass Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8edb4b",
   "metadata": {},
   "source": [
    "Up to this point, our focus was on **binary classification** to distinguishing between two classes. But what if we have more than two? How can we extend our approach to handle multi-class classification?\n",
    "\n",
    "The code below demonstrates the **One-vs-Rest (OvR)** strategy using logistic regression. We have data with three classes (0, 1, 2); three separate models are trained, and during prediction, the class with the highest confidence score is selected.\n",
    "\n",
    "#### ‚ö†Ô∏è Important Note\n",
    "Before moving on, take a look at the training data. It's important to emphasize that you should not plot, analyze, or use the validation/test data during training or visualization. Keep the test set **completely untouched** until the final evaluation. This ensures a fair and unbiased assessment of your model's selection and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_three_classes( noise=1.0)\n",
    "\n",
    "# Since the data is sparse, I make a larger validation set (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  test_size=0.3,    # 30% validation\n",
    "                                                  stratify =y,      # Stratified split\n",
    "                                                  shuffle  =True,   # Shuffle the data\n",
    "                                                  random_state=42)\n",
    "\n",
    "visualize_data(X_train, y_train, \"Regular Data (Training Set)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db958514",
   "metadata": {},
   "source": [
    "Here, I used scikit-learn's `Perceptron` that can handle OvR. After fitting the model to the training data, it predicts test labels and ebaluates accuracy. A confusion matrix further breaks down performance across the three classes. This approach shows how OvR allows binary models to be adapted for multi-class problems in an effective way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline: standardize, then train Perceptron\n",
    "ovr_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Perceptron(max_iter=100, eta0=0.5, random_state=42) )\n",
    "\n",
    "# Fit model\n",
    "ovr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = ovr_model.predict(X_val)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_boundary_decision(X_train, y_train, ovr_model, probabilistic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = ovr_model.predict(X_val)\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion = confusion_matrix(y_val, y_pred, labels=[0, 1, 2])\n",
    "labels = [\"Class 0\", \"Class 1\", \"Class 2\"]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(confusion, annot=True, fmt=\".1f\", cmap=\"gist_heat_r\",\n",
    "            xticklabels=labels, yticklabels=labels,\n",
    "            cbar=False, linewidths=1, linecolor=\"k\", \n",
    "            cbar_kws={'label': 'Number of Samples'})\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "\n",
    "plt.xticks(np.arange(3)+0.5, [0, 1, 2])  # Center tick labels\n",
    "plt.yticks(np.arange(3)+0.5, [0, 1, 2], rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866f76f",
   "metadata": {},
   "source": [
    "***\n",
    "### ‚úÖ Check your understanding\n",
    "\n",
    "- Let me challenge you with a question: Compare the results from the confusion matrix with the data classified by the decision boundary in your plot. Do they qualitatively match and **why**? For example, does the number of visibly misclassified points in the plot correspond to the misclassifications reported in the confusion matrix? Think carefully about this before moving on. Don't proceed without a clear explanation. I'll give the answer at the end of this session.\n",
    "\n",
    "### üí° Reflect and Run\n",
    "\n",
    "- Instead of the Perceptron, use the `LogisticRegression` and test your model. \n",
    "\n",
    "- Modify the data by changing the `noise` parameter in `make_three_classes` to noise=2.0. Now run the entire OvR-related codes. Analyze the Confusion Matrix and explain your observations. Use `accuracy_score` to measure the overall test accuracy.\n",
    "\n",
    "- What happens if you add the 4th class to the data? e.g., modify the `make_three_classes` function to accomodate 4 classes with the following centers (you can also write your new function named `make_four_classes`):\n",
    "```python\n",
    "[[0, 5], [2, 0], [5, 4], [2, 6]]\n",
    "```\n",
    "and now run your model again. Keep the noise level high, but you can modify it and set it to any value you like.\n",
    "\n",
    "- Why might certain classes be more difficult to distinguish from others?\n",
    "\n",
    "- To get answer to my question above: make a simple change when plotting the confusion matrix: Replace `X_val` with `X_train` in `ovr_model.predict(...)`, and replace `y_val` with `y_train` in `confusion_matrix(...)`. Now rerun the confusion matrix and compare it to what you saw in the decision boundary plot. Do you notice the connection? What exactly did I ask you to change ‚Äî and why does it matter?\n",
    "\n",
    "‚ö†Ô∏è **Note:** While this helps you visually connect predictions to what you see in the training plot, remember that the **correct setup for evaluating performance metrics (including confusion matrix)** is to always use the **validation or test data**, not the training set. The training set is for learning, not evaluation.\n",
    "\n",
    "***\n",
    "END\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
